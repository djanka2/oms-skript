
<!DOCTYPE html>


<html lang="de" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>11. Verfahren zweiter Ordnung &#8212; Optimierungsverfahren, Modellierung und Simulation (DSCB410)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=ca93fcec" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=91fba89f"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="_static/translations.js?v=70a09b52"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "Z": "\\mathbb{Z}", "R": "\\mathbb{R}", "B": "\\mathbb{B}", "I": "\\mathbb{I}", "norm": ["\\left\\lVert#1 \\right\\rVert", 1], "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\begin{pmatrix}"], "emat": ["\\end{pmatrix}"], "bmats": ["\\left(\\begin{smallmatrix}"], "emats": ["\\end{smallmatrix}\\right)"], "scikit": ["\\texttt{scikit-learn}"], "derv": ["\\frac{\\partial #1}{\\partial #2}", 2], "dervquad": ["\\frac{\\partial^2 #1}{\\partial #2^2}", 2], "dervzwei": ["\\frac{\\partial^2 #1}{\\partial {#2} \\partial {#3}}", 3], "v": ["\\mathbf{#1}", 1], "m": ["\\mathbf{#1}", 1], "argmin": ["\\underset{#1}{\\operatorname{arg\\!min}}", 1], "hyper": ["{\\color{Bittersweet}{#1}}", 1], "initial": "\\DeclareMathOperator{\\initial}{initial}", "reduced": "\\DeclareMathOperator{\\reduced}{reduced}", "lazy": "\\DeclareMathOperator{\\lazy}{lazy}", "ILP": "\\DeclareMathOperator{\\ILP}{ILP}", "red": ["{\\color{BrickRed}{#1}}", 1]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '11_Verfahren_zweiter_Ordnung';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Stichwortverzeichnis" href="genindex.html" />
    <link rel="search" title="Suche" href="search.html" />
    <link rel="next" title="12. Stochastischer Gradientenabstieg" href="12_Stochastischer_Gradientenabstieg.html" />
    <link rel="prev" title="10. Verfahren erster Ordnung" href="10_Gradientenverfahren.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="de"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="00_Ueberblick.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/HKA_IWI_Bildmarke-h_RGB.svg" class="logo__image only-light" alt="Optimierungsverfahren, Modellierung und Simulation (DSCB410) - Home"/>
    <script>document.write(`<img src="_static/HKA_IWI_Bildmarke-h_RGB.svg" class="logo__image only-dark" alt="Optimierungsverfahren, Modellierung und Simulation (DSCB410) - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Suche" aria-label="Suche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Suche</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="00_Ueberblick.html">
                    Überblick
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lineare Optimierungsmodelle</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_Grundbegriffe.html">1. Einführung und Grundbegriffe</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="02_Lineare_Probleme.html">2. Lineare Optimierung</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="02_Transportproblem.html">2.9. Anwendung: Transportproblem</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="03_Ganzzahlige_Probleme.html">3. Ganzzahlige Probleme</a></li>
<li class="toctree-l1"><a class="reference internal" href="04_Dynamische_Probleme.html">4. Zeitabhängige Probleme</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_Praxisaspekte.html">5. Praxisaspekte beim Lösen von gemischt-ganzzahligen Programmen</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ableitungsbasierte Optimierung</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="06_Multivariate_Analysis.html">6. Funktionen und Ableitungen</a></li>
<li class="toctree-l1"><a class="reference internal" href="07_Automatische_Differentiation.html">7. Automatische Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_Theoretische_Grundlagen.html">8. Grundlagen der nichtlinearen Optimierung</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_Quadratische_Probleme.html">9. Quadratische Probleme</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_Gradientenverfahren.html">10. Verfahren erster Ordnung</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">11. Verfahren zweiter Ordnung</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_Stochastischer_Gradientenabstieg.html">12. Stochastischer Gradientenabstieg</a></li>
<li class="toctree-l1"><a class="reference internal" href="13_Training_NN.html">13. Training von Neuronalen Netzen</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Laden Sie diese Seite herunter">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/11_Verfahren_zweiter_Ordnung.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Quelldatei herunterladen"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="In PDF drucken"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Vollbildmodus"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Suche" aria-label="Suche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Verfahren zweiter Ordnung</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Inhalt </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#newton-verfahren">11.1. Newton Verfahren</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exkurs-konvergenzgeschwindigkeit">11.1.1. Exkurs: Konvergenzgeschwindigkeit</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#newton-verfahren-fur-quadratische-funktionen">11.1.2. Newton Verfahren für quadratische Funktionen</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularisierung-des-verfahrens">11.1.3. Regularisierung des Verfahrens</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#newton-verfahren-als-methode-zur-bestimmung-von-nullstellen">11.1.4. Newton Verfahren als Methode zur Bestimmung von Nullstellen</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nachteile-des-newton-verfahrens">11.2. Nachteile des Newton Verfahrens</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quasi-newton-verfahren">11.3. Quasi-Newton Verfahren</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#idee-von-quasi-newton-verfahren">11.3.1. Idee von Quasi-Newton Verfahren</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#das-dfp-update">11.3.2. Das DFP-Update</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#das-bfgs-update">11.3.3. Das BFGS-Update</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limited-memory-bfgs">11.3.4. Limited-memory BFGS</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zusammenfassung-der-verfahren-erster-und-zweiter-ordnung">11.4. Zusammenfassung der Verfahren erster und zweiter Ordnung</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="verfahren-zweiter-ordnung">
<span id="sec-newton"></span><h1><span class="section-number">11. </span>Verfahren zweiter Ordnung<a class="headerlink" href="#verfahren-zweiter-ordnung" title="Link to this heading">#</a></h1>
<p>Bei Experimenten mit pathologischen Funktionen wie der Rosenbrock Funktion (siehe Übungen) stellt man fest, dass Gradientenverfahren sehr viele Schritte benötigen. Ein Problem ist, dass die Richtung des steilsten Abstiegs fast orthogonal auf der Richtung steht, die direkt zum Minimum führt, im folgenden Bild etwas unmathematisch “Tal des besten Abstiegs” genannt.</p>
<figure class="align-default" id="fig-rosenbrock">
<img alt="_images/newton_motivation.png" src="_images/newton_motivation.png" />
<figcaption>
<p><span class="caption-number">Abb. 11.1 </span><span class="caption-text">Typisches Verhalten eines Gradientenabstiegs für die Rosenbrock Funktion.</span><a class="headerlink" href="#fig-rosenbrock" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Im vergangen Kapitel haben wir gesehen, wie man dieses Zick-Zack Verhalten sowie das langsame “Kriechen” des Gradientenabstiegs durch einen Momentumsterm und Normalisierung verbessern kann. Dies funktioniert leider nicht in allen Fällen und es hat außerdem den Nachteil, dass man mit diesen Optionen immer mehr zusätzliche Hyperparameter einführt (Schrittweite, Schrittweitenstrategie, Parameter der Schrittweitenstrategie, Gewicht <span class="math notranslate nohighlight">\(\beta\)</span> des Momentumsterms, Normalisierung), die sorgfältig aufeinander abgestimmt werden müssen. Dies muss man potentiell für jede neue Funktion tun.</p>
<p>Wir schauen uns das Verhalten am Beispiel der Rosenbrock Funktion genauer an. Der Graph der <a class="reference external" href="https://en.wikipedia.org/wiki/Rosenbrock_function">Rosenbrock Funktion</a> (auch <em>Banana Valley Function</em>) ist ein gekrümmtes, steiles Tal, das an den Rändern sehr steil ist und bei dem Tal die Talsohle in einem bananenförmigen Verlauf nur leicht in Richtung des globalen Minimums <span class="math notranslate nohighlight">\((1,1)\)</span> abfällt. Die Funktion ist definiert als:</p>
<div class="math notranslate nohighlight">
\[ 
f(\v x) = (x_1-1)^2 + 100(x_1^2 - x_2)^2
\]</div>
<p>Ihre Hessematrix <span class="math notranslate nohighlight">\(H(\v x)=\nabla^2 f(\v x)\)</span> ist</p>
<div class="math notranslate nohighlight">
\[\begin{split}
H(\v x)=\bmat 2+1200x_1^2-400x_2 &amp; -400x_1\\
      -400x_1 &amp; 200 \emat
\end{split}\]</div>
<p>Wir werten die Hessematrix an einem Punkt in der Nähe der Lösung aus, z.B. <span class="math notranslate nohighlight">\((0.97,0.94)\)</span> (siehe schwarzer Punkt in <a class="reference internal" href="#fig-rosenbrock"><span class="std std-numref">Abb. 11.1</span></a>):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
H(0.97,0.94)=\bmat 2+1200 \cdot 0.97^2-400\cdot 0.94 &amp; -400\cdot 0.97\\
      -400\cdot 0.97 &amp; 200 \emat = \bmat 755.08 &amp; -388 \\ -388 &amp; 200\emat
\end{split}\]</div>
<p>Was sagen uns diese Werte? Noch gar nichts – wir erinnern uns, dass die Eigen<em>werte</em> der Hessematrix die Krümmung von <span class="math notranslate nohighlight">\(f\)</span> in Richtung der Eigen<em>vektoren</em> beschreiben. Berechnen wir also Eigenwerte und Eigenvektoren:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Gradient der Rosenbrock Funktion &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="mi">400</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="o">-</span><span class="mi">200</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>

<span class="k">def</span> <span class="nf">hess</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Hessematrix der Rosenbrock Funktion &quot;&quot;&quot;</span>
    <span class="n">ddf1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="o">+</span><span class="mi">1200</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="mi">400</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">400</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <span class="n">ddf2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">400</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">200</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">ddf1</span><span class="p">,</span> <span class="n">ddf2</span><span class="p">])</span>

<span class="n">x0</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.97</span><span class="p">,</span><span class="mf">0.94</span><span class="p">]</span>
<span class="n">lam</span><span class="p">,</span> <span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">hess</span><span class="p">(</span><span class="n">x0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Eigenwert 1:</span><span class="si">{</span><span class="n">lam</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">Eigenwert 2:</span><span class="si">{</span><span class="n">lam</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Eigenvektor 1:</span><span class="si">{</span><span class="n">e</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="se">\n</span><span class="s2">Eigenvektor 2:</span><span class="si">{</span><span class="n">e</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Richtung des steilsten Anstiegs:</span><span class="si">{</span><span class="n">grad</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">x0</span><span class="p">))</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Eigenwert 1:954.5855445761965
Eigenwert 2:0.49445542380334473
Eigenvektor 1:[ 0.88932258 -0.45728038]
Eigenvektor 2:[0.45728038 0.88932258]
Richtung des steilsten Anstiegs:[ 0.84898637 -0.52841475]
</pre></div>
</div>
</div>
</div>
<p>Wir stellen fest: Die Krümmung in Richtung <span class="math notranslate nohighlight">\(e_1=\bmats 0.89\\-0.46\emats\)</span> ist etwa 1900 Mal so groß wie in Richtung <span class="math notranslate nohighlight">\(e_2=\bmats 0.46\\0.89\emats\)</span>.</p>
<p>Schauen wir uns zum Vergleich die Richtung des steilsten Abstiegs am Punkt <span class="math notranslate nohighlight">\((0.97,0.94)\)</span> an: Der (normalisierte) Gradient von <span class="math notranslate nohighlight">\(f\)</span> ausgewertet am Punkt <span class="math notranslate nohighlight">\((0.97,0.94)\)</span> ist:</p>
<div class="math notranslate nohighlight">
\[ 
\frac{\nabla f(0.97,0.94)}{\norm{\nabla f(0.97,0.94)}_2}= \bmat 0.85,&amp;-0.52 \emat
\]</div>
<p>Wir sehen: die Richtung des steilsten Abstiegs (bzw. Anstiegs, aber das ist ja die gleiche Richtungsvektor nur mit dem Skalar <span class="math notranslate nohighlight">\(-1\)</span> multipliziert) ist der stark gekrümmten Richtung <span class="math notranslate nohighlight">\(e_1\)</span> sehr ähnlich. Das Verfahren macht Schritte in Richtungen sehr starker Krümmung (tatsächlich ist die Krümmung von <span class="math notranslate nohighlight">\(f\)</span> in Richtung des steilsten Anstiegs – oder Abstiegs, das Ergebnis ist dasselbe – gegeben durch <span class="math notranslate nohighlight">\(\nabla f(\v x)H(\v x) \nabla f(\v x)^T\)</span>, hier also <span class="math notranslate nohighlight">\(\bmats 0.85,&amp;-0.52 \emats \bmats 755.08 &amp; -388 \\ -388 &amp; 200\emats \bmats 0.85\\-0.52 \emats=179.6\)</span>).</p>
<p>Welche Konsequenz hat das? Dazu muss man sich vor Augen halten, dass <em>Krümmung</em> die <em>Änderung der Steigung</em> beschreibt. Eine starke Krümmung bedeutet eine große (lokale) Änderungsrate der Steigung. Anschaulich: Geht man ein sehr kleines Stück in eine Richtung, in der die Funktion stark gekrümmt ist, ist dort die Steigung plötzlich ganz anders. Im Falle des Gradientenabstiegs für die Rosenbrock Funktion: Geht man ein Stück in Richtung des steilsten Abstiegs, hat die Funktion dort keinen steilen Abstieg mehr, sondern nur einen flachen Abstieg oder sogar einen Anstieg. Das sagt uns ihre starke Krümmung.</p>
<p>Umgekehrt verspricht die Richtung der schwachen Krümmung, <span class="math notranslate nohighlight">\(e_2\)</span> (entspricht ungefähr dem “Tal des besten Abstiegs” im Bild) zwar lokal nur wenig Abstieg. Da sich die Steigung aber wenig ändert, könnte man durchaus einen größeren Schritt in diese Richtung gehen.</p>
<p>Diese Überlegungen konnten wir mit Hilfe der Hessematrix anstellen. Die Idee von Verfahren zweiter Ordnung ist es, lokale Krümmungsinformation zu benutzen um bessere Richtungen und Schrittweiten zu erhalten. Wir schauen uns im folgenden zwei Varianten dieser Verfahren ein: Das Newton Verfahren und Quasi-Newton Verfahren.</p>
<section id="newton-verfahren">
<h2><span class="section-number">11.1. </span>Newton Verfahren<a class="headerlink" href="#newton-verfahren" title="Link to this heading">#</a></h2>
<p>Der Gradientenabstieg basiert auf einer Taylor-Entwicklung erster Ordnung – einer Linearisierung. Mit Hilfe des Gradienten berechnet man eine lineare Approximation der Funktion und geht auf dieser linearen Funktion ein Stück bergab. Am neuen Punkt linearisiert man wieder usw. Wie weit man jeweils vom Linearisierungspunkt weggeht wird durch die Schrittweite gesteuert. Diese braucht man zwingend, denn da eine lineare Funktion kein Minimum hat, würde es dort ja beliebig lange bergab gehen.</p>
<p>Eine Idee, sich dem Newton Verfahren für Optimierung zu nähern ist folgende: Im Gegensatz zum Gradientenabstieg approximiert man die Funktion lokal nicht durch eine lineare, sondern eine quadratische Funktion. Diese minimiert man und wählt als nächste Iterierte das berechnete Minimum. Dort bildet man wieder eine quadratische Approximation usw.</p>
<p>Die quadratische Approximation erhält man – Sie ahnen es – mit Hilfe des Taylor-Polynoms zweiten Grades berechnet an der Entwicklungsstelle <span class="math notranslate nohighlight">\(\v x^{[k]}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
T(\v x^{[k]} + \v d)=f(\v x^{[k]})+\nabla f(\v x^{[k]})d+\frac{1}{2}\v d^T\v H(\v x^{[k]})\v d
\]</div>
<p>Dies ist eine quadratische Funktion in der Variablen <span class="math notranslate nohighlight">\(\v d\)</span>. Wie wir am Ende von <a class="reference internal" href="08_Theoretische_Grundlagen.html#sec-konvex"><span class="std std-ref">Konvexität</span></a> gesehen haben, hat eine quadratische Funktion ein eindeutiges Minimum, wenn die Hessematrix <span class="math notranslate nohighlight">\(H(\v x^{[k]})\)</span> positiv definit ist (dann ist die Funktion strikt konvex). Weiterhin haben wir in <a class="reference internal" href="08_Theoretische_Grundlagen.html#ex:quadratic">Example 8.5</a> gesehen, dass man den kritischen Punkt einer quadratischen Funktion durch Lösung eines linearen Gleichungssystems bestimmen kann.</p>
<p>Diese Lösung wäre dann der Schritt <span class="math notranslate nohighlight">\(\v d^{[k]}\)</span>, mit dem wir zur nächsten Iterierten <span class="math notranslate nohighlight">\(\v x^{[k+1]}\)</span> kommen.</p>
<p>Wir berechnen den kritischen Punkt des Taylor Polynoms. Es muss gelten <span class="math notranslate nohighlight">\(\nabla T=0\)</span>, also</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\nabla T(\v x^{[k]} + \v d) &amp;= \nabla f(\v x^{[k]})+\v H(\v x^{[k]})\v d=0\\
&amp;=\v H(\v x^{[k]})\v d = -\nabla f(\v x^{[k]})
\end{align*}\]</div>
<p>Falls <span class="math notranslate nohighlight">\(\v H(\v x^{[k]})\)</span> invertierbar ist, ergibt sich die optimale Suchrichtung durch:</p>
<div class="math notranslate nohighlight">
\[
\v d=-\v H(\v x^{[k]})^{-1}\nabla f(\v x^{[k]})
\]</div>
<p>Aber Achtung: dies ist nur für positiv definite <span class="math notranslate nohighlight">\(\v H(\v x^{[k]})\)</span> eine Abstiegsrichtung, denn sonst hätte die quadratische Approximation ja ein Maximum statt ein Minimum.</p>
<p>Insgesamt haben wir also folgenden Algorithmus, der sich gut in <a class="reference internal" href="10_Gradientenverfahren.html#alg:gd_allgemein">Algorithm 10.3</a> aus dem letzten Abschnitt einfügt:</p>
<div class="proof algorithm admonition" id="alg:newton">
<p class="admonition-title"><span class="caption-number">Algorithm 11.1 </span> (Newton Verfahren zur Optimierung von Funktionen)</p>
<section class="algorithm-content" id="proof-content">
<dl class="simple myst">
<dt>Gegeben:</dt><dd><p>Zwei Mal differenzierbare Funktion <span class="math notranslate nohighlight">\(f:\R^n\rightarrow\R\)</span>.</p>
</dd>
<dt>Gesucht:</dt><dd><p>Lokales Minimum von <span class="math notranslate nohighlight">\(f\)</span>.</p>
</dd>
</dl>
<p><strong>Algorithmus</strong>:</p>
<p>Starte mit initialer Schätzung <span class="math notranslate nohighlight">\(\v x^{[0]}\)</span>, setze <span class="math notranslate nohighlight">\(k=0\)</span>.</p>
<p>Für <span class="math notranslate nohighlight">\(k=0,1,2,\dots\)</span>:</p>
<ol class="arabic">
<li><p>Überprüfe, ob <span class="math notranslate nohighlight">\(\v x^{[k]}\)</span> die <strong>Abbruchbedingung</strong> erfüllt.</p>
<ul class="simple">
<li><p>Falls ja: Abbruch mit Lösung <span class="math notranslate nohighlight">\(\v x^{[k]}\)</span></p></li>
<li><p>Falls nein: gehe zu Schritt 2.</p></li>
</ul>
</li>
<li><p>Bestimme <strong>Abstiegsrichtung</strong> <span class="math notranslate nohighlight">\(\v d^{[k]}\)</span> durch</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \v d^{[k]}=-\v H(\v x^{[k]})^{-1}\nabla f(\v x^{[k]})^T
    \end{align*}\]</div>
</li>
<li><p><em>Optional:</em> Bestimme Schrittweite <span class="math notranslate nohighlight">\(\alpha^{[k]}\)</span>.</p></li>
<li><p>Berechne neue Iterierte <span class="math notranslate nohighlight">\(\v x^{[k+1]}=\v x^{[k]}+\alpha^{[k]}\v d^{[k]}\)</span>.</p></li>
</ol>
</section>
</div><p>Einige Anmerkungen zu dem Verfahren:</p>
<ol class="arabic simple">
<li><p>Die Inverse der Hessematrix modifiziert nicht nur die Richtung, sondern auch die Schrittlänge geeignet. Oft wird deshalb <span class="math notranslate nohighlight">\(\alpha^{[k]}=1\)</span> gesetzt, d.h. es wird “unsichtbar”.</p></li>
<li><p>Voraussetzung, dass das Verfahren zu einem Minimum konvergiert ist, dass die Hessematrix positiv definit sein muss. Sonst ist nämlich <span class="math notranslate nohighlight">\(\v d^{[k]}\)</span> keine Abstiegsrichtung. Positive Definitheit der Hessematrix ist in der Nähe der Lösung zwar gegeben, aber weit weg von der Lösung (z.B. bei einem x-beliebigen Startwert) ist das nicht immer der Fall.</p></li>
</ol>
<p>Wir schauen uns das Verfahren am Beispiel der Rosenbrock Funktion an.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Function to minimize &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">100</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span>
    
<span class="k">def</span> <span class="nf">df</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Derivative of the function to minimize &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="mi">400</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="o">-</span><span class="mi">200</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>

<span class="k">def</span> <span class="nf">ddf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; 2nd Derivative of the function to minimize &quot;&quot;&quot;</span>
    <span class="n">ddf1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="o">+</span><span class="mi">1200</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="o">-</span><span class="mi">400</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">400</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span>
    <span class="n">ddf2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">400</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">200</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">ddf1</span><span class="p">,</span> <span class="n">ddf2</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">newton</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">derv</span><span class="p">,</span> <span class="n">hessian</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">alpha0</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Perform n_steps iterations of newton&#39;s method and return iterates &quot;&quot;&quot;</span>
    <span class="n">x_history</span> <span class="o">=</span> <span class="p">[</span><span class="n">x0</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps</span><span class="p">):</span>
        <span class="c1"># Evaluate gradient</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">derv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># Stop if norm (length) of gradient vector is small</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">g</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-6</span><span class="p">:</span>
            <span class="k">break</span>

        <span class="c1"># Descent direction</span>
        <span class="n">H</span> <span class="o">=</span> <span class="n">hessian</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">d</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">H</span><span class="p">)</span><span class="nd">@g</span>

        <span class="c1"># Step length</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha0</span>

        <span class="c1"># Next iterate</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">d</span>

        <span class="c1"># Store iterate for analysis</span>
        <span class="n">x_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_history</span><span class="p">)</span>

<span class="n">x0</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">newton</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">ddf</span><span class="p">,</span> <span class="n">x0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-1.,  1.],
       [ 1., -3.],
       [ 1.,  1.]])
</pre></div>
</div>
</div>
</div>
<p>Wow! Die Funktion, mit der sich das Gradientenverfahren so abgeplagt hat, erledigt das Newton Verfahren in nur wenigen Iterationen. Tatsächlich hat das Newton Verfahren eine starke Eigenschaft, nämlich <em>lokal quadratische</em> Konvergenz.</p>
<section id="exkurs-konvergenzgeschwindigkeit">
<h3><span class="section-number">11.1.1. </span>Exkurs: Konvergenzgeschwindigkeit<a class="headerlink" href="#exkurs-konvergenzgeschwindigkeit" title="Link to this heading">#</a></h3>
<p>Numerische Verfahren, die eine Folge von Iterierten <span class="math notranslate nohighlight">\(\v x^{[k]}\)</span>, <span class="math notranslate nohighlight">\(k=1,2,\dots\)</span> produzieren, kann man anhand ihrer Konvergenzgeschwindigkeit charakterisieren. Die Analyse der Konvergenzgeschwindigkeit ist ein theoretisches Konstrukt und dient dazu, das Verhalten von Verfahren in der Nähe einer (exakten) Lösung <span class="math notranslate nohighlight">\(\v x^*\)</span> zu erklären.</p>
<p>Folgende drei Fälle spielen dabei in der Praxis eine Rolle:</p>
<dl class="simple myst">
<dt>Lineare Konvergenz</dt><dd><p>Ein Verfahren konvergiert (lokal) <strong>linear</strong>, wenn für aufeinanderfolgende Iterierte <span class="math notranslate nohighlight">\(\v x^{[k]}\)</span> und <span class="math notranslate nohighlight">\(\v x^{[k+1]}\)</span> gilt:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \frac{\left\|\v x^{[k+1]}-\v x^*\right\|}{\left\|\v x^{[k]}-\v x^*\right\|}\leq c &lt; 1,\quad \text{für }k\rightarrow \infty
    \end{align*}\]</div>
<p>In Worten: Der Abstand zur Lösung nach dem Schritt ist <span class="math notranslate nohighlight">\(c\cdot100\%\)</span> des Abstandes vor dem Schritt. Der Zugewinn wird also kleiner, je näher man der Lösung kommt. Je kleiner dabei der Wert <span class="math notranslate nohighlight">\(c\)</span> ist, desto besser. Das deckt sich mit unserer empirischen Beobachtung beim Gradientenverfahren. Dieses ist ein linear konvergentes Verfahren.</p>
</dd>
<dt>Quadratische Konvergenz</dt><dd><p>Ein Verfahren konvergiert (lokal) <strong>quadratisch</strong>, wenn für aufeinanderfolgende Iterierte <span class="math notranslate nohighlight">\(\v x^{[k]}\)</span> und <span class="math notranslate nohighlight">\(\v x^{[k+1]}\)</span> gilt:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \frac{\left\|\v x^{[k+1]}-\v x^*\right\|}{\left\|\v x^{[k]}-\v x^*\right\|^2}\leq c &lt; 1,\quad   \text{für }k\rightarrow \infty
    \end{align*}\]</div>
<p>Die Definition ist etwas technisch und ihre Konsequenzen sind möglicherweise nicht direkt klar. Es bedeutet aber in der Praxis, dass sich in der Nähe der Lösung mit jedem Schritt die Anzahl der korrekten Dezimalstellen in etwa <em>verdoppelt</em> – also eine sehr rapide Konvergenz.
Die Konvergenzordnung des Newton Verfahrens ist lokal quadratisch.</p>
</dd>
<dt>Superlineare Konvergenz</dt><dd><p>Ein Verfahren konvergiert (lokal) <strong>superlinear</strong>, wenn für aufeinanderfolgende Iterierte <span class="math notranslate nohighlight">\(\v x^{[k]}\)</span> und <span class="math notranslate nohighlight">\(\v x^{[k+1]}\)</span> gilt:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \frac{\left\|\v x^{[k+1]}-\v x^*\right\|}{\left\|\v x^{[k]}-\v x^*\right\|}\leq c_k,
    \end{align*}\]</div>
<p>wobei <span class="math notranslate nohighlight">\(c_k\)</span> eine Folge ist, die gegen <span class="math notranslate nohighlight">\(0\)</span> konvergiert. Ein Verfahren, das superlinear konvergiert, konvergiert schneller als ein lineare konvergentes Verfahren aber in der Regel langsamer als ein quadratisch konvergentes.</p>
</dd>
</dl>
<p>Man sollte noch hervorheben, dass die Konvergenz des Newton Verfahrens <em>lokal</em> quadratisch ist. Lokal bedeutet “in der Nähe” der Lösung, was sich oft nicht einfach charakterisieren lässt. Weiter weg von der Lösung verliert es diese Eigenschaft (auch wenn die Hessematrix positiv definit ist). Man kann das Newton Verfahren z.B. mittels einer Liniensuche global konvergent machen. Das heißt, es konvergiert dann von beliebigen Startwerten aus, aber unter Umständen nicht mehr so schnell.</p>
</section>
<section id="newton-verfahren-fur-quadratische-funktionen">
<h3><span class="section-number">11.1.2. </span>Newton Verfahren für quadratische Funktionen<a class="headerlink" href="#newton-verfahren-fur-quadratische-funktionen" title="Link to this heading">#</a></h3>
<p>Wir haben das Newton Verfahren als lokale Approximation durch ein Taylor-Polynom zweiter Ordnung eingeführt, welches exakt minimiert wird. Das bedeutet aber, dass das Newton Verfahren für eine quadratische Funktion von einem beliebigen Startwert aus konvergiert. Wir rechnen das nach. Sei also</p>
<div class="math notranslate nohighlight">
\[
f(\v x)=\frac{1}{2}\v x^T\v A\v x+\v b^T\v x+c,
\]</div>
<p>eine quadratische Funktion mit positiv definiter Hessematrix <span class="math notranslate nohighlight">\(\v A\)</span>. Dann kann man das Minimum einerseits analytisch bestimmen durch</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
&amp;\nabla f(\v x)=\v A\v x + \v b=0 \Leftrightarrow \v x=-\v A^{-1}\v b
\end{align*}\]</div>
<p>Andererseits berechnen wir den ersten Schritt des Newton Verfahrens mit beliebigem Startwert <span class="math notranslate nohighlight">\(\v x^{[0]}\)</span>:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\v x^{[1]}=\v x^{[0]}-\v H(\v x^{[0]})^{-1}\nabla f(\v x^{[0]})^T=\v x^{[0]}-\v A^{-1}(\v A\v x^{[0]}+\v b)=-\v A^{-1}\v b
\end{align*}\]</div>
<p>Unabhängig vom Startwert landet das Verfahren in derselben Lösung <span class="math notranslate nohighlight">\(\v A^{-1}\v b\)</span></p>
</section>
<section id="regularisierung-des-verfahrens">
<h3><span class="section-number">11.1.3. </span>Regularisierung des Verfahrens<a class="headerlink" href="#regularisierung-des-verfahrens" title="Link to this heading">#</a></h3>
<p>Wir haben weiter oben schon darauf hingewiesen, dass die Richtung <span class="math notranslate nohighlight">\(H(\v x^{[k]})\nabla f(\v x^{[k]})\)</span>Newton nur für positiv definite <span class="math notranslate nohighlight">\(\v H(\v x^{[k]})\)</span> eine Abstiegsrichtung ist. Falls das nicht der Fall sein sollte, kann die Hessematrix <em>regularisieren</em> um einen Abstieg zu erwzingen. Dafür muss man eine Zahl <span class="math notranslate nohighlight">\(\lambda^{[k]}&gt;0\)</span> bestimmen, so dass</p>
<div class="math notranslate nohighlight">
\[
\v H(\v x^{[k]}) + \lambda^{[k]}\I
\]</div>
<p>positiv definit ist. <span class="math notranslate nohighlight">\(\I\)</span> steht hier für die Einheitsmatrix. Man kann zeigen, dass <span class="math notranslate nohighlight">\(\lambda^{[k]}\)</span> mindestens so groß sein muss wie der Betrag des kleinsten Eigenwertes von <span class="math notranslate nohighlight">\(\v H(\v x^{[k]})\)</span> (da <span class="math notranslate nohighlight">\(\v H(\v x^{[k]})\)</span> nicht positiv definit ist, ist dieser auf jeden Fall negativ).</p>
<p>Der regularisierte Newton Schritt ist dann</p>
<div class="math notranslate nohighlight">
\[
\v x^{[k+1]}=\v x^{[k]} - (\v H(\v x^{[k]}) + \lambda^{[k]}\I)^{-1}\nabla f(\v x^{[k]})^T
\]</div>
<p>Typischerweise wird man versuchen <span class="math notranslate nohighlight">\(\lambda^{[k]}\)</span> so klein wie möglich zu wählen. Es aber interessant festzustellen, dass sich die Abstiegsrichtung des regularisierten Newton Schrittes mit steigendem <span class="math notranslate nohighlight">\(\lambda^{[k]}\)</span> immer mehr der Richtung des steilsten Abstiegs annähert. Allerdings wird der Schritt mit sehr kleiner Schrittweite, proportional zu <span class="math notranslate nohighlight">\(\frac{1}{\lambda^{[k]}}\)</span> ausgeführt.</p>
</section>
<section id="newton-verfahren-als-methode-zur-bestimmung-von-nullstellen">
<h3><span class="section-number">11.1.4. </span>Newton Verfahren als Methode zur Bestimmung von Nullstellen<a class="headerlink" href="#newton-verfahren-als-methode-zur-bestimmung-von-nullstellen" title="Link to this heading">#</a></h3>
<p>Ursrpünglich wurde das Newton Verfahren nicht als Optimierungsverfahren erfunden, sondern als Methode um nichtlineare Gleichungen zu lösen. Das Lösen nichtlinearer Gleichungen ist aber dasselbe wie die Nullstellen von Funktionen zu bestimmen. Nullstellenprobleme sind Probleme der Form <span class="math notranslate nohighlight">\(\v g (\v x)=\v 0\)</span>, wobei <span class="math notranslate nohighlight">\(\v g:\R^n\rightarrow\R^n\)</span> eine vektorwertige Funktion ist (historisch wurden nur Polynomfunktionen untersucht). Die Iterationsvorschrift für das Nullstellenproblem lautet</p>
<div class="math notranslate nohighlight">
\[
\v x^{[k+1]}=\v x^{[k]}-\nabla \v g(\v x^{[k]})^{-1}\v g(\v x^{[k]})
\]</div>
<p>Im Kontext der Optimierung kann man sich das Newton Verfahren als einen Ansatz zum iterativen Lösen der Optimalitätsbedingungen erster Ordnung, <span class="math notranslate nohighlight">\(\nabla f(\v x)=\v 0\)</span> vorstellen (<span class="math notranslate nohighlight">\(\nabla f(\v x)\)</span> spielt dann die Rolle der Funktion <span class="math notranslate nohighlight">\(\v g\)</span>). Das erklärt auch das Verhalten des Newton Verfahrens, möglicherweise zu Maxima oder Sattelpunkten zu konvergieren, da die Optimalitätsbedingungen erster Ordnung zwischen diesen ja auch keinen Unterschied machen. Erklärungen zum klassischen Newton Verfahren für Nullstellen findet man z.B. <a class="reference external" href="https://de.wikipedia.org/wiki/Newtonverfahren">hier</a>.</p>
</section>
</section>
<section id="nachteile-des-newton-verfahrens">
<h2><span class="section-number">11.2. </span>Nachteile des Newton Verfahrens<a class="headerlink" href="#nachteile-des-newton-verfahrens" title="Link to this heading">#</a></h2>
<p>Wir haben im vorherigen Abschnitt gesehen, wie das Newton-Verfahrens gegenüber Verfahren erster Ordnung ein dramatische beschleunigtes Konvergenzverhalten aufweisen kann. Leider gehen damit einige Nachteile einher, die wir hier noch einmal kurz zusammenfassen.</p>
<dl class="simple myst">
<dt>Auswertung der Hessematrix</dt><dd><p>In jedem Schritt müssen alle zweiten Ableitungen ausgewertet werden. Dies sind, da die Hessematrix eine symmetrische <span class="math notranslate nohighlight">\(n\times n\)</span>-Matrix ist, <span class="math notranslate nohighlight">\(n(n+1)/2\)</span> Terme. Bei komplizierten Funktionen stellt das einen erheblichen Mehraufwand pro Iteration dar.</p>
</dd>
<dt>Invertierung der Hessematrix</dt><dd><p>In jeder Iteration muss die Hessematrix invertiert werden. Genauer gesagt: es muss ein lineares Gleichungssystem in <span class="math notranslate nohighlight">\(n\)</span> Gleichungen und <span class="math notranslate nohighlight">\(n\)</span> Variablen gelöst werden. Dies geschieht ebenfalls mit Hilfe numerischer Algorithmen (z.B. der <a class="reference external" href="https://de.wikipedia.org/wiki/Cholesky-Zerlegung">Cholesky-Zerlegung</a>), deren Rechenaufwand in der Regel kubisch mit der Anzahl der Variablen wächst. Das bedeutet, für die doppelte Anzahl an Variablen entsteht der <span class="math notranslate nohighlight">\(2^3=8\)</span>-fache Aufwand.</p>
</dd>
<dt>Keine Abstiegsrichtung</dt><dd><p>Abseits der Lösung kann es sein, dass die Hessematrix nich positiv definit ist. In diesem Fall ist der Newton-Schritt keine Abstiegs-, sondern eine Aufstiegsrichtung. Man kann den Newton-Schritt dann regularisieren. Dies ist aber mit zusätzlichem Aufwand verbunden und die entstehenden Abstiegsrichtung ähnelt einem (kurzen) Gradientenabstiegsschritt.</p>
</dd>
<dt>Speicherplatz</dt><dd><p>Neben dem Rechenaufwand für die Berechnung des Schrittes ist auch der benötigte Speicherplatz nicht zu untersätzen. Beispiel: Die Hessematrix einer Funktion mit <span class="math notranslate nohighlight">\(10000\)</span> Variablen besitzt <span class="math notranslate nohighlight">\(10000\cdot 10001/2=50005000\)</span> Einträge. Wenn jeder Eintrag <span class="math notranslate nohighlight">\(8\)</span> Bytes belegt, wären das etwa <span class="math notranslate nohighlight">\(400\)</span> MB. Bei <span class="math notranslate nohighlight">\(20000\)</span> Variablen beträgt der Speicherplatzbedarf bereits <span class="math notranslate nohighlight">\(1.6\)</span> GB.</p>
</dd>
</dl>
</section>
<section id="quasi-newton-verfahren">
<h2><span class="section-number">11.3. </span>Quasi-Newton Verfahren<a class="headerlink" href="#quasi-newton-verfahren" title="Link to this heading">#</a></h2>
<section id="idee-von-quasi-newton-verfahren">
<h3><span class="section-number">11.3.1. </span>Idee von Quasi-Newton Verfahren<a class="headerlink" href="#idee-von-quasi-newton-verfahren" title="Link to this heading">#</a></h3>
<p>Quasi-Newton Verfahren versuchen, den Vorteil der schnellen Konvergenz von Verfahren zweiter Ordnung beizubehalten, aber dabei die Nachteile zu umgehen. Die Grundidee ist es, eine Approximation der Hessematrix bzw. ihrer Inversen zu konstruieren und diese in jedem Schritt des Abstiegsverfahren basierend auf der vorherigen Iteration zu aktualisieren statt komplett neu zu berechnen.</p>
<p>Wir konzentrieren uns zunächst den ersten der vier Nachteile des Newton-Verfahrens: die Notwendigkeit, zweite Ableitungen auszuwerten, um Krümmungsinformation zu erhalten. Denn wie wir gesehen haben, produziert die Krümmungsinformation bessere Abstiegsrichtungen. Können wir Krümmungsinformation nicht auch bekommen, ohne zweite Ableitungen zu berechnen? Dazu betrachten wir zunächst ein eindimensionales Beispiel, das illustriert, was unter “Krümmung” eigentlich zu verstehen ist. Wir betrachten die Funktion</p>
<div class="math notranslate nohighlight">
\[
f(x)=\frac{1}{4}x^4-3x^2-8x
\]</div>
<p>Die Steigung der Sekante an die Funktion <span class="math notranslate nohighlight">\(f\)</span>, die durch zwei Iterierte <span class="math notranslate nohighlight">\(x^{[k]}\)</span> und <span class="math notranslate nohighlight">\(x^{[k+1]}\)</span> geht, kann man als Approximation der <em>Tangentensteigung</em> im Punkt <span class="math notranslate nohighlight">\(x^{[k+1]}\)</span> betrachten, also der ersten Ableitung:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
f'(x^{[k+1]})\approx \frac{f(x^{[k+1]})-f(x^{[k]})}{x^{[k+1]}-x^{[k]}}\label{eq:sek1}
\end{align*}\]</div>
<figure class="align-default" id="id4">
<a class="reference internal image-reference" href="_images/sekante1.png"><img alt="_images/sekante1.png" src="_images/sekante1.png" style="width: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Abb. 11.2 </span><span class="caption-text">Sekante an <span class="math notranslate nohighlight">\(f(x)\)</span> als Approximation der ersten Ableitung im Punkt <span class="math notranslate nohighlight">\(x^{[k+1]}\)</span>.</span><a class="headerlink" href="#id4" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Mit dem gleichen Argument kann man die Steigung der Sekante an die erste Ableitung <span class="math notranslate nohighlight">\(f'\)</span> als Approximation der Tangentensteigung der ersten Ableitung im Punkt <span class="math notranslate nohighlight">\(x^{[k+1]}\)</span> betrachten, also der zweiten Ableitung:</p>
<div class="math notranslate nohighlight" id="equation-eq-sek1">
<span class="eqno">(11.1)<a class="headerlink" href="#equation-eq-sek1" title="Link to this equation">#</a></span>\[
f''(x^{[k+1]})\approx \frac{f'(x^{[k+1]})-f'(x^{[k]})}{x^{[k+1]}-x^{[k]}}
\]</div>
<figure class="align-default" id="id5">
<a class="reference internal image-reference" href="_images/sekante2.png"><img alt="_images/sekante2.png" src="_images/sekante2.png" style="width: 400px;" /></a>
<figcaption>
<p><span class="caption-number">Abb. 11.3 </span><span class="caption-text">Sekante an <span class="math notranslate nohighlight">\(f'(x)\)</span> als Approximation der zweiten Ableitung im Punkt <span class="math notranslate nohighlight">\(x^{[k+1]}\)</span>.</span><a class="headerlink" href="#id5" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Wir führen folgende Abkürzungen ein:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
s^{[k]}&amp;:=x^{[k+1]}-x^{[k]}\\
g^{[k]}&amp;:=f'(x^{[k+1]})-f'(x^{[k]})
\end{align*}\]</div>
<p>Damit können wir die Gleichung <a class="reference internal" href="#equation-eq-sek1">(11.1)</a> schreiben als:</p>
<div class="math notranslate nohighlight" id="equation-eq-sek2">
<span class="eqno">(11.2)<a class="headerlink" href="#equation-eq-sek2" title="Link to this equation">#</a></span>\[
f''(x^{[k+1]})\approx \frac{g^{[k]}}{s^{[k]}}
\]</div>
<p>oder auch</p>
<div class="math notranslate nohighlight" id="equation-eq-sek3">
<span class="eqno">(11.3)<a class="headerlink" href="#equation-eq-sek3" title="Link to this equation">#</a></span>\[
f''(x^{[k+1]})s^{[k]}\approx g^{[k]}
\]</div>
<p>Wir nennen <a class="reference internal" href="#equation-eq-sek3">(11.3)</a> die <em>Sekantenbedingung</em>. Der Unterschied zwischen <a class="reference internal" href="#equation-eq-sek2">(11.2)</a> und <a class="reference internal" href="#equation-eq-sek3">(11.3)</a> ist, dass man <a class="reference internal" href="#equation-eq-sek3">(11.3)</a> auch für mehrdimensionale Funktionen formulieren kann:</p>
<div class="math notranslate nohighlight" id="equation-eq-sek4">
<span class="eqno">(11.4)<a class="headerlink" href="#equation-eq-sek4" title="Link to this equation">#</a></span>\[
\nabla^2 f(\v x^{[k+1]})\v s^{[k]}\approx \v g^{[k]}
\]</div>
<p>Die zweite Ableitung <span class="math notranslate nohighlight">\(\nabla^2 f(\v x^{[k+1]})\)</span> ist nun eine quadratische und symmetrische Matrix, <span class="math notranslate nohighlight">\(\v s^{[k]}\)</span> und <span class="math notranslate nohighlight">\(\v g^{[k]}\)</span> sind Vektoren. Die Aussage <a class="reference internal" href="#equation-eq-sek4">(11.4)</a> ist also eine Aussage für eine bestimmte <em>Richtung</em>, nämlich <span class="math notranslate nohighlight">\(\v s^{[k]}\)</span>, die Richtung des letzten Schritts.</p>
<p>Diese Sekantenbedingung ist die Grundlage von Quasi-Newton Verfahren und sie führt zu einigen der erfolgreichsten Verfahren für ableitungsbasierte Optimierung. Wir möchten einerseits die Hessematrix einer mehrdimensionalen Funktion <span class="math notranslate nohighlight">\(\nabla^2 f\)</span> mit einer Matrix <span class="math notranslate nohighlight">\(\v B^{[k]}\)</span> approximieren, andererseits aber <span class="math notranslate nohighlight">\(\nabla^2 f\)</span> nicht berechnen. Wir fordern von unserer Approximation, dass sie die Krümmung wenigstens in eine Richtung <span class="math notranslate nohighlight">\(\v s^{[k]}\)</span> approximiert. Dies ist eine Näherung für die zweite Ableitung in dieser Richtung. Wir wollen also, dass</p>
<div class="math notranslate nohighlight">
\[
\v B^{[k+1]}\v s^{[k]}=\v g^{[k]},
\]</div>
<p>wobei <span class="math notranslate nohighlight">\(\v s^{[k]}=\v x^{[k+1]}-\v x^{[k]}\)</span> der Schritt und <span class="math notranslate nohighlight">\(g^{[k]}:=\nabla f(x^{[k+1]})^T-\nabla f(x^{[k]})^T\)</span> die Differenz der Gradienten (als Spaltenvektor) ist.</p>
<p>Zusammenfassend: Wir suchen eine Matrix <span class="math notranslate nohighlight">\(\v B^{[k+1]}\)</span>, für die gilt:</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\v B^{[k+1]}\)</span> erfüllt die Sekantenbedingung <span class="math notranslate nohighlight">\(\v B^{[k+1]}\v s^{[k]}=\v g^{[k]}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\v B^{[k+1]}\)</span> ist symmetrisch, wie die Hessematrix</p></li>
<li><p><span class="math notranslate nohighlight">\(\v B^{[k+1]}\)</span> ist positiv definit, damit Abstieg garantiert ist.</p></li>
</ol>
<p>Da eine symmetrische <span class="math notranslate nohighlight">\(n\times n\)</span>-Matrix mehr Einträge, also Freiheitsgrade hat als die Anzahl dieser Bedingungen, gibt es viele Matrizen, die alle diese Bedingungen erfüllen, genauer gesagt: unendlich viele.</p>
</section>
<section id="das-dfp-update">
<h3><span class="section-number">11.3.2. </span>Das DFP-Update<a class="headerlink" href="#das-dfp-update" title="Link to this heading">#</a></h3>
<p>Die Idee des <em>Davidon-Fletcher-Powell-Updates</em> <em>(DFP-Update)</em> ist es, die neue Approximation <span class="math notranslate nohighlight">\(\v B^{[k+1]}\)</span> als diejenige Matrix zu wählen, die die drei Bedingungen oben erfüllt und die am <em>nächsten</em> an der aktuellen Approximation <span class="math notranslate nohighlight">\(\v B^{[k]}\)</span> liegt, d.h.</p>
<div class="math notranslate nohighlight">
\[
\v B^{[k+1]} = \argmin{} \norm{\v B-\v B^{[k]}}
\]</div>
<p>Das <span class="math notranslate nohighlight">\(\argmin{B}\)</span> bedeutet: <span class="math notranslate nohighlight">\(\v B^{[k+1]}\)</span> soll aus allen Matrizen <span class="math notranslate nohighlight">\(\v B\)</span>, die die drei Bedingungen oben erfüllen, diejenige sein, für die der Ausdruck <span class="math notranslate nohighlight">\(\norm{\v B-\v B^{[k]}}\)</span> minimal wird. Je nachdem, welche Matrixnorm man hier benutzt, erhält man unterschiedliche Hessematrix Approximationen als Lösung dieses Problems. Für die Frobenius-Norm (quadriere alle Einträge der Matrix, bilde die Summe und ziehe die Wurzel – also genauso wie die Euklidische Norm für Vektoren funktioniert) kann man theoretisch beweisen, dass dies für folgende Matrix <span class="math notranslate nohighlight">\(\v B^{[k+1]}\)</span> der Fall ist (der Einfachheit halber lassen wir auf der rechten Seite das Superscript <span class="math notranslate nohighlight">\(^{[k]}\)</span> weg, d.h. <span class="math notranslate nohighlight">\(\v B:=\v B^{[k]}, \v s=\v s^{[k]}, \v g=\v g^{[k]}\)</span>):</p>
<div class="math notranslate nohighlight" id="equation-eq-dfp">
<span class="eqno">(11.5)<a class="headerlink" href="#equation-eq-dfp" title="Link to this equation">#</a></span>\[
\v B^{[k+1]}=\left( \I - \frac{\v g\v s^T}{\v g^T\v s}\right)\v B
\left( \I - \frac{\v s\v g^T}{\v g^T\v s}\right)+\frac{\v g\v g^T}{\v g^T\v s}
\]</div>
<p>Bevor wir in die Details dieser kompliziert anmutenden Formel eintauchen, stellen wir fest, dass die Berechnung von <span class="math notranslate nohighlight">\(\v B^{[k+1]}\)</span> nur auf drei Größen basiert:</p>
<ol class="arabic simple">
<li><p>Die aktuelle Approximation der Hessematrix <span class="math notranslate nohighlight">\(\v B:=\v B^{[k]}\)</span>.</p></li>
<li><p>Die Differenz der Gradienten aus der aktuellen und der vorherigen Iteration: <span class="math notranslate nohighlight">\(\v g=\v g^{[k]}=\nabla f(\v x^{[k+1]})^T-\nabla f(\v x^{[k]})^T\)</span>.</p></li>
<li><p>Die Differenz der Iterierten aus der aktuellen und der vorherigen Iteration (der Schritt): <span class="math notranslate nohighlight">\(\v s^{[k]}=\v x^{[k+1]}-\v x^{[k]}\)</span>.</p></li>
</ol>
<p>Dies ist eine weitere zentrale Idee von Quasi-Newton Verfahren: die Verwendung von <em>Update-Formeln</em> für die Berechnung der Approximation der Hessematrix, die nur Größen verwenden, die ohnehin in der akuellen Iteration verfügbar sind. Die Update-Formeln sehen zwar kompliziert aus, der Rechenaufwand ist aber relativ gering. Schauen wir uns die einzelnen Elemente der Berechnung einmal genauer an:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\v g^T\v s\)</span> ist ein Skalar, der durch die Multiplikation des Zeilenvektors <span class="math notranslate nohighlight">\(\v g^T\)</span> mit dem Spaltenvektor <span class="math notranslate nohighlight">\(\v s\)</span> entsteht.  <span class="math notranslate nohighlight">\(\v g^T\v s\)</span> ist ein Spezialfall eines <em>inneren Produktes</em></p></li>
<li><p>Die Ausdrücke <span class="math notranslate nohighlight">\(\v g\v s^T\)</span>, <span class="math notranslate nohighlight">\(\v s\v g^T\)</span> und <span class="math notranslate nohighlight">\(\v g\v g^T\)</span> sind sogenannte <em>äußere Produkte</em>: Ein Spaltenvektor multipliziert mit einem Zeilenvektor ergibt ein Matrix vom Rang 1.</p></li>
<li><p>Schließlich bezeichnet <span class="math notranslate nohighlight">\(\I\)</span> noch die <span class="math notranslate nohighlight">\(n\times n\)</span> Einheitsmatrix.</p></li>
</ul>
<p>Die Matrix <span class="math notranslate nohighlight">\(\v B=\v B^{[k]}\)</span> wird also von links und rechts mit einer Matrix multipliziert und anschließend wird eine weitere Rang 1-Matrix <span class="math notranslate nohighlight">\(\frac{\v g\v g^T}{\v g^T\v s}\)</span> addiert.</p>
<p>Es stellt sich heraus, dass die Update Formel einen weiteren Vorteil gegenüber der exakten Hessematrix hat: Statt einer Approximation der Hessematrix kann man auch eine Approximation der <em>Inversen</em> der Hessematrix vorhalten und updaten.
Mit der <a class="reference external" href="https://de.wikipedia.org/wiki/Sherman-Morrison-Woodbury-Formel">Sherman-Morrison-Woodbury-Formel</a> kann man die Formeln analytisch umformulieren und erhält folgende Formel für die Approximation der Inversen <span class="math notranslate nohighlight">\(\v A^{[k+1]}=(\v B^{[k+1]})^{-1}\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eq-dfp-inv">
<span class="eqno">(11.6)<a class="headerlink" href="#equation-eq-dfp-inv" title="Link to this equation">#</a></span>\[
\v A^{[k+1]}=\v A-\frac{\v A \v g\v g^T \v A}{\v g^T\v A \v g}+\frac{\v s \v s^T}{\v g^T \v s}
\]</div>
<p>Damit wäre auch der zweite Nachteil des Newton-Verfahrens, die Notwendigkeit, in jeder Iteration eine Matrix zu invertieren, behoben.</p>
<p>Eine Updateformel ist natürlich noch kein fertiger Algorithmus. Bevor wir uns ein komplettes Quasi-Newton Verfahren anschauen, schauen wir uns noch eine zweite Update-Formel an. Das DFP-Update wurde zuerst von W. C. Davidon entdeckt<a class="footnote-reference brackets" href="#fn-davidon" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> und 1960 unabhängig von Fletcher und Powell beschrieben. Der Erfolg des Verfahrens führte zu einer verstärkten Forschungsaktivität im Bereich der Quasi-Newton Methoden. Im Jahre 1970 entdeckten die vier Autoren Broyden, Fletcher, Goldfarb und Shanno schließlich unabhängig(!) voneinander<a class="footnote-reference brackets" href="#fn-bfgs" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a> das bis heute erfolgreichste und meistgenutzte Quasi-Newton Update.</p>
</section>
<section id="das-bfgs-update">
<h3><span class="section-number">11.3.3. </span>Das BFGS-Update<a class="headerlink" href="#das-bfgs-update" title="Link to this heading">#</a></h3>
<p>Das <em>Broyden-Fletcher-Goldfarb-Shanno-Update</em> <em>(BFGS-Update)</em> lässt sich auf ähnlichem Wege herleiten wie das DFP-Update. Statt von der Sekantenbedingung <span class="math notranslate nohighlight">\(\v B^{[k+1]}\v s^{[k]}=\v g^{[k]}\)</span> auszugehen, formuliert man die Sekantenbedingung um</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\v B^{[k+1]}\v s^{[k]}&amp;=\v g^{[k]}\\ \Leftrightarrow (\v B^{[k+1]})^{-1}\v B^{[k+1]}\v s^{[k]}&amp;=(\v B^{[k+1]})^{-1}\v g^{[k]}
\end{align*}\]</div>
<p>Mit der Kurzform <span class="math notranslate nohighlight">\(\v A^{[k+1]}=(\v B^{[k+1]})^{-1}\)</span> erhält man die äquivalente Form der Sekantenbedingung <span class="math notranslate nohighlight">\(\v A^{[k+1]}\v g^{[k]}=\v s^{[k]}\)</span>. Ein ähnliches Argument wie beim DFP Update – die Approximation soll die äquivalente Sekantenbedingung erfüllen, symmetrisch sein und möglichst nahe bei der aktuellen Approximation liegen – führt zum BFGS Update. Wie beim DFP-Update kann man entweder eine Approximation der Hessematrix <span class="math notranslate nohighlight">\(\v B^{[k+1]}\)</span> oder der Inverse <span class="math notranslate nohighlight">\(\v A^{[k+1]}\)</span> vorhalten. Die Formeln lauten:</p>
<div class="math notranslate nohighlight" id="equation-eq-bfgs">
<span class="eqno">(11.7)<a class="headerlink" href="#equation-eq-bfgs" title="Link to this equation">#</a></span>\[
\v B^{[k+1]}=\v B-\frac{\v B \v s\v s^T \v B}{\v s^T\v B \v s}+\frac{\v g \v g^T}{\v s^T \v g}
\]</div>
<p>für die Approximation der Hessematrix und</p>
<div class="math notranslate nohighlight" id="equation-eq-bfgs-inv">
<span class="eqno">(11.8)<a class="headerlink" href="#equation-eq-bfgs-inv" title="Link to this equation">#</a></span>\[
\v A^{[k+1]}=\left( \I - \frac{\v s\v g^T}{\v s^T\v g}\right)\v A
\left( \I - \frac{\v g\v s^T}{\v s^T\v g}\right)+\frac{\v s\v s^T}{\v s^T\v g}
\]</div>
<p>für ihre Inverse. Beim Vergleich der Formeln <a class="reference internal" href="#equation-eq-bfgs-inv">(11.8)</a> und <a class="reference internal" href="#equation-eq-dfp">(11.5)</a> bzw. <a class="reference internal" href="#equation-eq-bfgs">(11.7)</a> und <a class="reference internal" href="#equation-eq-dfp-inv">(11.6)</a> fällt auf, dass DFP-Update und BFGS-Update <em>dual</em> zueinander sind. Man erhält das eine aus dem anderen, indem man die Buchstaben <span class="math notranslate nohighlight">\(\v A\)</span> und <span class="math notranslate nohighlight">\(\v B\)</span> sowie <span class="math notranslate nohighlight">\(\v s\)</span> und <span class="math notranslate nohighlight">\(\v g\)</span> miteinander vertauscht.</p>
<p>Eine weitere wichtige Eigenschaft der beiden Update-Formeln ist die Tatsache, dass es <em>Rang-2 Updates</em> sind: Die ursprüngliche Approximation <span class="math notranslate nohighlight">\(\v B^{[k]}\)</span> wird modifiziert, indem zwei Rang-1-Matrizen (äußere Produkte von Vektoren) als “Korrekturterme” addiert werden. Die rekursive Definition bedeutet auch, dass man mit einer Matrix vollen Ranges starten muss. Häufig nimmt man hier eine skalierte Einheitsmatrix oder auch die (dann einmalig auszuwertende) exakte Hessematrix.</p>
<p>Es gibt viele weitere Rang-2-Updates, die ähnlich funktionieren wie das DFP und das BFGS-Update. Das BFGS-Update wird am häufigsten verwendet, da es (empirisch) die besten Resultate liefert, d.h. die besten Abstiegsrichtungen. Das vollständige <em>BFGS-Verfahren</em> sieht wie folgt aus:</p>
<div class="proof algorithm admonition" id="alg:bfgs">
<p class="admonition-title"><span class="caption-number">Algorithm 11.2 </span> (BFGS Verfahren)</p>
<section class="algorithm-content" id="proof-content">
<dl class="simple myst">
<dt>Gegeben:</dt><dd><p>Differenzierbare Funktion <span class="math notranslate nohighlight">\(f:\R^n\rightarrow\R\)</span>.</p>
</dd>
<dt>Gesucht:</dt><dd><p>Lokales Minimum von <span class="math notranslate nohighlight">\(f\)</span>.</p>
</dd>
</dl>
<p><strong>Algorithmus</strong>:</p>
<p>Starte mit initialer Schätzung <span class="math notranslate nohighlight">\(\v x^{[0]}\)</span> und <span class="math notranslate nohighlight">\(\v A^{[0]}\)</span>, setze <span class="math notranslate nohighlight">\(k=0\)</span>.</p>
<p>Für <span class="math notranslate nohighlight">\(k=0,1,2,\dots\)</span>:</p>
<ol class="arabic">
<li><p>Überprüfe, ob <span class="math notranslate nohighlight">\(\v x^{[k]}\)</span> die <strong>Abbruchbedingung</strong> erfüllt.</p>
<ul class="simple">
<li><p>Falls ja: Abbruch mit Lösung <span class="math notranslate nohighlight">\(\v x^{[k]}\)</span></p></li>
<li><p>Falls nein: gehe zu Schritt 2.</p></li>
</ul>
</li>
<li><p>Bestimme <strong>Abstiegsrichtung</strong> <span class="math notranslate nohighlight">\(\v d^{[k]}\)</span> durch</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \v d^{[k]}=-\v A{[k]}^{-1}\nabla f(\v x^{[k]})^T
    \end{align*}\]</div>
</li>
<li><p>Bestimme <strong>Schrittweite</strong> <span class="math notranslate nohighlight">\(\alpha^{[k]}\)</span> durch Liniensuche.</p></li>
<li><p>Berechne neue <strong>Iterierte</strong> <span class="math notranslate nohighlight">\(\v x^{[k+1]}=\v x^{[k]}+\alpha^{[k]}\v d^{[k]}\)</span>.</p>
<p>Setze</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \v s^{[k]}&amp;=\alpha^{[k]}\v d^{[k]}\\
    \v g^{[k]}&amp;=\nabla f(\v x^{[k]})^T-\nabla f(\v x^{[k+1]})^T
    \end{align*}\]</div>
</li>
<li><p>Berechne neue Approximation der Inversen der Hessematrix <span class="math notranslate nohighlight">\(\v A^{[k+1]}\)</span> aus <span class="math notranslate nohighlight">\(\v A^{[k]}, \v s^{[k]}\)</span> und <span class="math notranslate nohighlight">\(\v g^{[k]}\)</span> mit dem <strong>BFGS-Update</strong>.</p></li>
</ol>
</section>
</div><p>Anmerkungen zu dem Verfahren:</p>
<ul class="simple">
<li><p>Wenn im ersten Schritt für <span class="math notranslate nohighlight">\(\v A^{[0]}\)</span> die Einheitsmatrix <span class="math notranslate nohighlight">\(\I\)</span> gewählt wird, entspricht der erste Schritt im Verfahren einem Gradientenabstieg.</p></li>
<li><p>Durch eine geeignete Liniensuche (backtracking Liniensuche) kann man erreichen, dass <span class="math notranslate nohighlight">\(\v A^{[k+1]}\)</span> immer positiv definit ist, wenn <span class="math notranslate nohighlight">\(\v A^{[k]}\)</span> positiv definit war.</p></li>
<li><p>Die Folge <span class="math notranslate nohighlight">\(\v A^{[k]}\)</span>, <span class="math notranslate nohighlight">\(k=0,1,2,\dots\)</span> konvergiert nicht unbedingt gegen die echte Hessematrix, d.h. im Grenzfall erhält man nicht unbedingt das Newton Verfahren.</p></li>
</ul>
<p>Wir schauen uns das Verfahren anhand eines numerischen Beispiels an.</p>
<div class="proof example admonition" id="example-2">
<p class="admonition-title"><span class="caption-number">Example 11.1 </span></p>
<section class="example-content" id="proof-content">
<p>Es soll die Funktion <span class="math notranslate nohighlight">\(f(x_1,x_2)=x_1^2+0.5x_2^2+3\)</span> minimiert werden. Der Gradient von <span class="math notranslate nohighlight">\(f\)</span> ist <span class="math notranslate nohighlight">\(\nabla f(x_1,x_2)=2x_1+x_2\)</span>. Wir zeigen den ersten Schritt des BFGS-Verfahrens.</p>
<p>Der Startwert für die Iterierte sei <span class="math notranslate nohighlight">\(\v x^{[0]}=\bmats 1\\2\emats\)</span> und der Startwert für die Hessematrix Approximation sei die Einheitsmatrix <span class="math notranslate nohighlight">\(\v A^{[0]}=\bmats 1&amp;0\\0&amp;1\emats\)</span>. Der Einfachheit halber nehmen wir an, das <span class="math notranslate nohighlight">\(\alpha^{[k]}=1\)</span>.</p>
<dl class="simple myst">
<dt><span class="math notranslate nohighlight">\(k=0\)</span></dt><dd><ul>
<li><p>Abstiegsrichtung bestimmen:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \v d^{[0]}=-\v A^{[0]}\nabla f(1,2)^T=-\bmat 1&amp;0\\0&amp;1\emat\bmat 2\\2\emat=\bmat -2\\-2\emat
    \end{align*}\]</div>
</li>
<li><p>Nächste Iterierte:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \v x^{[1]} &amp;= \v x^{[0]}+\v d^{[0]}=\bmat -1\\0 \emat\\
    \v s^{[0]} &amp;= \bmat -2\\ -2\emat\\
    \v g^{[0]} &amp;= \nabla f(-1,0)^T-\nabla f(1,2)^T=\bmat -2\\0\emat -\bmat 2\\2 \emat=\bmat -4\\-2\emat
    \end{align*}\]</div>
</li>
<li><p>BFGS Update (denken Sie sich das Superscript <span class="math notranslate nohighlight">\(^{[0]}\)</span> dazu):</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \v A^{[1]}=\left( \I - \frac{\v s\v g^T}{\v s^T\v g}\right)\v A
\left( \I - \frac{\v g\v s^T}{\v s^T\v g}\right)+\frac{\v s\v s^T}{\v s^T\v g}
    \end{align*}\]</div>
<p>Mit <span class="math notranslate nohighlight">\(\v s^T\v g = (-2)(-4)+(-2)(-2)=12\)</span> ergibt sich</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \v A^{[1]}&amp;=\left( \bmat 1&amp;0\\0&amp;1\emat - \frac{1}{12}\bmat 8&amp;4\\8&amp;4\emat\right)\bmat 1&amp;0\\0&amp;1\emat
\left( \bmat 1&amp;0\\0&amp;1\emat - \frac{1}{12}\bmat 8&amp;4\\8&amp;4\emat\right)+\frac{1}{12}\bmat 4&amp;4\\4&amp;4\emat\\
    &amp;=\frac{1}{9}\bmat 5&amp;-1\\-1&amp;11\emat
    \end{align*}\]</div>
</li>
</ul>
</dd>
<dt><span class="math notranslate nohighlight">\(k=1\)</span></dt><dd><ul>
<li><p>Abstiegsrichtung bestimmen:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \v d^{[1]}=-\v A^{[1]}\nabla f(-1,0)^T=-\frac{1}{9}\bmat 5&amp;-1\\-1&amp;11\emat\bmat -2\\0\emat=\frac{1}{9}\bmat 10\\-2\emat
    \end{align*}\]</div>
</li>
<li><p>usw.</p></li>
</ul>
</dd>
</dl>
</section>
</div><p>Das BFGS-Verfahren behebt drei der vier Nachteile des Newton-Verfahrens (Auswertung der Hessematrix, Invertierung der Hessematrix, positive Definitheit) und tatsächlich ist das BFGS-Verfahren für viele Optimierungsprobleme eine gute Wahl. Es braucht meist mehr Iterationen als das Newton-Verfahren. Auch die theoretischen Konvergenzeigenschaften sind etwas schlechter als beim Newton-Verfahren, es konvergiert <em>superlinear</em>. Allerdings ist es oft trotzdem schneller, da eine Iteration wesentlich weniger aufwendig ist. Es ist außerdem erheblich schneller als ein Gradientenabstieg, da bereits ein wenig Krümmungsinformation (wie sie durch das BFGS-Update reflektiert wird) ausreicht, um bessere Iterierte zu erzeugen und mehr Fortschritt in Richtung der Lösung zu erzielen.</p>
</section>
<section id="limited-memory-bfgs">
<h3><span class="section-number">11.3.4. </span>Limited-memory BFGS<a class="headerlink" href="#limited-memory-bfgs" title="Link to this heading">#</a></h3>
<p>Ein Nachteil des Newton-Verfahrens wird durch das normale BFGS-Update jedoch nicht beseitigt, nämlich dass man die gesamte Hessematrix(-approximation) bzw. deren Inverse speichern muss. Für große Optimierungsprobleme ist der Speicherbedarf alles andere als vernachlässigbar. So benötigt man für ein Optimierungsproblem mit <span class="math notranslate nohighlight">\(25,000\)</span> Variablen ca. <span class="math notranslate nohighlight">\(25,000 \times 25,000 \times 8\)</span> Byte <span class="math notranslate nohighlight">\(=5\)</span> Gigabyte Speicherplatz (oder etwa die Hälfte, wenn nur die obere Dreiecksmatrix gespeichert wird).</p>
<p>Die Idee des <em>Limited-memory BFGS-Verfahrens</em> (<em>L-BFGS-Verfahren</em>) ist es, nur Krümmungsinformation aus den letzten <span class="math notranslate nohighlight">\(m\)</span> Iterationen zu verwenden, wobei <span class="math notranslate nohighlight">\(m\)</span> nicht zu groß gewählt wird, etwa <span class="math notranslate nohighlight">\(m=20\)</span>. Die Motivation dahinter ist, dass die Krümmungsinformation an dem Punkt, an dem das Verfahren vor mehr als <span class="math notranslate nohighlight">\(m\)</span> Iterationen war, nicht mehr relevant für die aktuelle Iteration ist, da die Funktion in der Umgebung der aktuellen Iteration wahrscheinlich ganz anders gekrümmt ist. Den Begriff <em>memory</em> kann man hier auch mit dem Wort <em>Gedächtnis</em> übersetzen. Wie hilft uns das bei unserem anderen <em>memory</em>-Problem, nämlich dem <em>Speicherplatz</em>-Problem?</p>
<p>Zunächst ist klar, das die vollständige Krümmungsinformation der letzten <span class="math notranslate nohighlight">\(m\)</span> Iterationen implizit in den Vektoren <span class="math notranslate nohighlight">\(\v s^{[k-i]}, \v g^{[k-i]}\)</span>, <span class="math notranslate nohighlight">\(i=1,\dots,m\)</span> steckt. Das Ziel des L-BFGS-Verfahrens ist, anstatt der gesamten Matrix nur diese <span class="math notranslate nohighlight">\(2m\)</span> Vektoren zu speichern, die das BFGS-Update <em>implizit</em> repräsentieren. Wie können wir aber die Hessematrix <span class="math notranslate nohighlight">\(\v A^{[k]}\)</span> benutzen, ohne sie explizit aus den Vektoren <span class="math notranslate nohighlight">\(\v s^{[k-i]}\)</span> und <span class="math notranslate nohighlight">\(\v g^{[k-i]}\)</span> aufzubauen?</p>
<p>Wenn wir uns <a class="reference internal" href="#alg:bfgs">Algorithm 11.2</a> anschauen, stellen wir fest, dass das Verfahren die Matrix <span class="math notranslate nohighlight">\(\v A^{[k]}\)</span> nur benötigt, um den Schritt zu berechnen:</p>
<div class="math notranslate nohighlight">
\[
\v d^{[k]}=-\v A^{[k]}\nabla f(\v x^{[k]})^T
\]</div>
<p>Wir brauchen also nicht die Matrix <span class="math notranslate nohighlight">\(\v A^{[k]}\)</span>, sondern Matrix-Vektor Produkte  <span class="math notranslate nohighlight">\(\v A^{[k]}f(\v x^{[k]})^T\)</span>. Dies kann man tatsächlich nur mittels inneren Produkten und Summen von Vektoren erreichen. Für die Details dieses Algorithmus sei auf die Literatur verwiesen<a class="footnote-reference brackets" href="#fn-l-bfgs" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>. Zusammenfassend: Man kann das Matrix-Vektor Produkt mit der BFGS-Approximation <span class="math notranslate nohighlight">\(\v A^{[k]}f(\v x^{[k]})^T\)</span> berechnen, ohne die BFGS-Approximation <span class="math notranslate nohighlight">\(\v A^{[k]}\)</span> zu kennen. Es reicht aus, die Vektoren <span class="math notranslate nohighlight">\(\v s^{[k]}\)</span>  und <span class="math notranslate nohighlight">\(\v g^{[k]}\)</span> aus den letzten <span class="math notranslate nohighlight">\(m\)</span> Iterationen zu speichern. Dadurch wird Speicherplatz gespart.</p>
<p>Damit können wir den vollständigen L-BFGS Algorithmus skizzieren:</p>
<div class="proof algorithm admonition" id="alg:lbfgs">
<p class="admonition-title"><span class="caption-number">Algorithm 11.3 </span> (Limited-memory BFGS Verfahren)</p>
<section class="algorithm-content" id="proof-content">
<dl class="simple myst">
<dt>Gegeben:</dt><dd><p>Differenzierbare Funktion <span class="math notranslate nohighlight">\(f:\R^n\rightarrow\R\)</span>.</p>
</dd>
<dt>Gesucht:</dt><dd><p>Lokales Minimum von <span class="math notranslate nohighlight">\(f\)</span>.</p>
</dd>
</dl>
<p><strong>Algorithmus</strong>:</p>
<p>Gegeben: <span class="math notranslate nohighlight">\(m&gt;0\)</span>. Starte mit initialer Schätzung <span class="math notranslate nohighlight">\(\v x^{[0]}\)</span>, setze <span class="math notranslate nohighlight">\(k=0\)</span>.</p>
<p>Für <span class="math notranslate nohighlight">\(k=0,1,2,\dots\)</span>:</p>
<ol class="arabic">
<li><p>Überprüfe, ob <span class="math notranslate nohighlight">\(\v x^{[k]}\)</span> die <strong>Abbruchbedingung</strong> erfüllt.</p>
<ul class="simple">
<li><p>Falls ja: Abbruch mit Lösung <span class="math notranslate nohighlight">\(\v x^{[k]}\)</span></p></li>
<li><p>Falls nein: gehe zu Schritt 2.</p></li>
</ul>
</li>
<li><p>Wähle initiale Approximation der Hessematrix <span class="math notranslate nohighlight">\(\v A_0^{[k]}\)</span>.</p></li>
<li><p>Bestimme <strong>Abstiegsrichtung</strong></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \v d^{[k]}=-\v A{[k]}^{-1}\nabla f(\v x^{[k]})^T
    \end{align*}\]</div>
<p>durch “matrixfreies” Matrix-Vektor Produkt mit der BFGS-Approximation der Inversen der Hessematrix. Benutze dazu die Vektorpaaren <span class="math notranslate nohighlight">\(\{\v s^{[k-i]},\v g^{[k-i]}\}\)</span>, <span class="math notranslate nohighlight">\(i=1,\dots,m\)</span>.</p>
</li>
<li><p>Bestimme <strong>Schrittweite</strong> <span class="math notranslate nohighlight">\(\alpha^{[k]}\)</span> durch Liniensuche.</p></li>
<li><p>Berechne neue <strong>Iterierte</strong> <span class="math notranslate nohighlight">\(\v x^{[k+1]}=\v x^{[k]}+\alpha^{[k]}\v d^{[k]}\)</span>.</p></li>
<li><p>Falls <span class="math notranslate nohighlight">\(k&gt;m\)</span>: Lösche Vektorpaar <span class="math notranslate nohighlight">\(\{\v s^{[k-m]},\v g^{[k-m]}\}\)</span> aus dem Speicher.</p></li>
<li><p>Setze</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \v s^{[k]}&amp;=\alpha^{[k]}\v d^{[k]}\\
    \v g^{[k]}&amp;=\nabla f(\v x^{[k]})^T-\nabla f(\v x^{[k+1]})^T
    \end{align*}\]</div>
<p>und füge <span class="math notranslate nohighlight">\(\{\v s^{[k]},\v g^{[k]}\}\)</span> zum Speicher hinzu.</p>
</li>
</ol>
</section>
</div><p>Anmerkungen:</p>
<ul class="simple">
<li><p>Schritt 2: Da man das Update in jedem Schritt ja aus den letzten <span class="math notranslate nohighlight">\(m\)</span> Iterationen neu aufbaut, kann man auch in jedem Schritt eine andere initiale Hessematrix-Approximation wählen.</p></li>
<li><p>In den ersten <span class="math notranslate nohighlight">\(m\)</span> Iterationen produzieren BFGS und L-BFGS die gleichen Iterierten (bei gleicher Wahl der <span class="math notranslate nohighlight">\(\v A_0^{[k]}=\v A^{[0]}\)</span>). Danach unterscheiden Sie sich, da im BFGS Update immer noch Spuren von allen Iterationen vorhanden sind, während das L-BFGS Update diese explizit nicht berücksichtigt (die entsprechenden Vektoren <span class="math notranslate nohighlight">\(\v s^{[k-m]}, \v g^{[k-m]}\)</span> werden gelöscht).</p></li>
</ul>
<p>L-BFGS ist für viele unbeschränkte Optimierungsprobleme das Mittel das Wahl. Es ist</p>
<ul class="simple">
<li><p>Effizient in der Laufzeit</p></li>
<li><p>Effizient im Speicherbedarf</p></li>
<li><p>Relativ robust, es müssen nur wenige Hyperparameter getunt werden</p></li>
<li><p>Es sind gute Implementierungen verfügbar, z.B. in <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/optimize.minimize-lbfgsb.html">scipy</a>.</p></li>
</ul>
</section>
</section>
<section id="zusammenfassung-der-verfahren-erster-und-zweiter-ordnung">
<h2><span class="section-number">11.4. </span>Zusammenfassung der Verfahren erster und zweiter Ordnung<a class="headerlink" href="#zusammenfassung-der-verfahren-erster-und-zweiter-ordnung" title="Link to this heading">#</a></h2>
<p>In den vergangenen beiden Kapiteln haben wir eine ganze Reihe von Verfahren zur Minimierung von differenzierbaren Funktionen kennengelernt. Alle Verfahren haben folgende Gemeinsamkeiten:</p>
<ol class="arabic simple">
<li><p>Sie finden <em>lokale</em> Minima von Funktionen. Das Suchen eines <em>globalen</em> Minimums nicht-konvexer Funktionen ist eine wesentlich schwierigere Aufgabe. Stand heute kann das in vertretbarer Zeit nur für Funktionen mit wenigen dutzend Variablen geleistet werden. Ein pragmatischer Ansatz, die vorgestellten Verfahren zu verbessern, ist der <em>multi-start</em> Ansatz: man startet das Verfahren mehrmals von unterschiedlichen Startwerten und hofft, dass es zu unterschiedlichen Minima konvergiert. Unter diesen wählt man das das beste aus.</p></li>
<li><p>Für viele der Verfahren kann theoretisch bewiesen werden, dass sie konvergieren. In der Praxis kann aber doch noch einiges schief gehen: zum einen ist nie gesagt nach <em>wie vielen</em> Schritten die Verfahren konvergieren, zum anderen rechnet man in der Regel mit endlicher Präzision, d.h. numerische Rundungsfehler können dazu führen, dass ein Verfahren in der Praxis nicht konvergiert.</p></li>
<li><p>Alle Verfahren arbeiten erzeugen eine Folge von <em>Iterierten</em>, d.h. Vektoren <span class="math notranslate nohighlight">\(\v x^{[0]}, \v x^{[1]}, \v x^{[2]},\dots\)</span>. Die nächste Iterierte wird aus der vorherigen mit einer <em>Abstiegsrichtung</em> <span class="math notranslate nohighlight">\(\v d^{[k]}\)</span> mutlipliziert mit einer skalaren <em>Schrittweite</em> <span class="math notranslate nohighlight">\(\alpha^{[k]}\)</span> gewonnen: <span class="math notranslate nohighlight">\(\v x^{[k+1]}=\v x^{[k]}+\alpha^{[k]}\v d^{[k]}\)</span>. Den Unterschied <span class="math notranslate nohighlight">\(\v x^{[k+1]}-\v x^{[k]}\)</span> nennt man auch <em>Schritt</em>.</p></li>
<li><p>Alle Verfahren benötigen neben dem Funktionswert an einer beliebigen Stelle auch den Wert der Ableitung (erste und/oder zweite) an einer beliebigen Stelle.</p></li>
</ol>
<p>Die folgende Tabelle gibt eine Übersicht über die vorgestellten Verfahren</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Name</p></th>
<th class="head"><p>Abstiegsrichtung</p></th>
<th class="head"><p>Schrittweitensteuerung</p></th>
<th class="head"><p>Vorteile</p></th>
<th class="head"><p>Nachteile</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Gradientenabstieg</p></td>
<td><p><span class="math notranslate nohighlight">\(\v d^{[k]}\)</span><span class="math notranslate nohighlight">\(=-\nabla f(\v x^{[k]})^T\)</span></p></td>
<td><p>- Konstant<br>- Dämpfung<br>- Liniensuche</p></td>
<td><p>- Einfach zu implementieren<br>- Einfach zu verstehen</p></td>
<td><p>- Langsame Konvergenz da oft schlechte Abstiegsrichtung<br>- Zick-Zack-Verhalten<br>- Kriechverhalten in flachen Gegenden</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Gradientenabstieg <br> mit Momentum</p></td>
<td><p><span class="math notranslate nohighlight">\(\v d^{[k]}\)</span><span class="math notranslate nohighlight">\(=\beta \v d^{[k-1]}-\nabla f(\v x^{[k]})^T\)</span></p></td>
<td><p>- Konstant<br>- Dämpfung<br>- Liniensuche</p></td>
<td><p>Zick-Zack- und Kriechverhalten wird abgemildert</p></td>
<td><p>- Evtl. keine gute Abstiegsrichtung<br>- Evtl. zu viel Momentum in der Nähe der Lösung</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Normalisierter <br>Gradientenabstieg</p></td>
<td><p><span class="math notranslate nohighlight">\(\v d^{[k]}\)</span><span class="math notranslate nohighlight">\(=-\frac{\nabla f(\v x^{[k]})^T}{\norm{\nabla f(\v x^{[k]})}}_2\)</span></p></td>
<td><p>- Konstant<br>- Dämpfung<br>- Liniensuche</p></td>
<td><p>Kriechverhalten wird abgemildert</p></td>
<td><p>Alle sonstigen Nachteile des Gradientenabstiegs</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Newton-Verfahren</p></td>
<td><p><span class="math notranslate nohighlight">\(\v d^{[k]}\)</span><span class="math notranslate nohighlight">\(=-\nabla^2f(\v x^{[k]})^{-1}\nabla f(\v x^{[k]})^T\)</span></p></td>
<td><p>Nicht notwendig</p></td>
<td><p>Lokal sehr schnelle Konvergenz</p></td>
<td><p>- Auswertung der Hessematrix in jedem Schritt <br> - Invertierung der Hessematrix in jedem Schritt <br> - Speicherplatzbedarf <br> - Evtl. keine Abstiegsrichtung</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>BFGS-Verfahren</p></td>
<td><p><span class="math notranslate nohighlight">\(\v d^{[k]}\)</span><span class="math notranslate nohighlight">\(=-\v A^{[k]}\nabla f(\v x^{[k]})^T\)</span></p></td>
<td><p>Liniensuche</p></td>
<td><p>- Lokal schnelle Konvergenz <br> - Einfache Berechnung der Approximation der Inversen der Hessematrix <br> - Abstiegsrichtung garantiert</p></td>
<td><p>Speicherplatzbedarf bei großen Problem</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>L-BFGS-Verfahren</p></td>
<td><p><span class="math notranslate nohighlight">\(\v d^{[k]}\)</span><span class="math notranslate nohighlight">\(=-\v A^{[k]}\nabla f(\v x^{[k]})^T\)</span></p></td>
<td><p>Liniensuche</p></td>
<td><p>- Lokal (oft) schnelle Konvergenz <br> - Einfache Berechnung der Approximation der Inversen der Hessematrix <br> - Abstiegsrichtung garantiert <br> - Geringer Speicherplatzbedarf</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="fn-davidon" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p><em>William Davidon: Variable metric method for minimization. In: Argonne National Laboratory (Hrsg.): A.E.C. Research and Development Report. ANL-5990, 1959.</em></p>
</aside>
<aside class="footnote brackets" id="fn-bfgs" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p><em>Charles G. Broyden: The convergence of a class of double-rank minimization algorithms. In: Journal of the Institute of Mathematics and Its Applications. Band 6, 1970, S. 76–90, doi:10.1093/imamat/6.1.76.</em></p>
<p><em>Roger Fletcher: A New Approach to Variable Metric Algorithms. In: Computer Journal. Band 13, Nr. 3, 1970, S. 317–322, doi:10.1093/comjnl/13.3.317.</em></p>
<p><em>Donald Goldfarb: A Family of Variable Metric Updates Derived by Variational Means. In: Mathematics of Computation. Band 24, Nr. 109, 1970, S. 23–26, doi:10.1090/S0025-5718-1970-0258249-6.</em></p>
<p><em>David F. Shanno: Conditioning of quasi-Newton methods for function minimization. In: Mathematics of Computation. Band 24, Nr. 111, Juli 1970, S. 647–656, doi:10.1090/S0025-5718-1970-0274029-X.</em></p>
</aside>
<aside class="footnote brackets" id="fn-l-bfgs" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id3">3</a><span class="fn-bracket">]</span></span>
<p>Algorithm 7.4 (S. 177) in J. Nocedal, und S. J. Wright. Numerical Optimization. 2nd ed. Springer Series in Operations Research. New York: Springer, 2006.</p>
</aside>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="10_Gradientenverfahren.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">zurück</p>
        <p class="prev-next-title"><span class="section-number">10. </span>Verfahren erster Ordnung</p>
      </div>
    </a>
    <a class="right-next"
       href="12_Stochastischer_Gradientenabstieg.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">weiter</p>
        <p class="prev-next-title"><span class="section-number">12. </span>Stochastischer Gradientenabstieg</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Inhalt
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#newton-verfahren">11.1. Newton Verfahren</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#exkurs-konvergenzgeschwindigkeit">11.1.1. Exkurs: Konvergenzgeschwindigkeit</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#newton-verfahren-fur-quadratische-funktionen">11.1.2. Newton Verfahren für quadratische Funktionen</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularisierung-des-verfahrens">11.1.3. Regularisierung des Verfahrens</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#newton-verfahren-als-methode-zur-bestimmung-von-nullstellen">11.1.4. Newton Verfahren als Methode zur Bestimmung von Nullstellen</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nachteile-des-newton-verfahrens">11.2. Nachteile des Newton Verfahrens</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quasi-newton-verfahren">11.3. Quasi-Newton Verfahren</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#idee-von-quasi-newton-verfahren">11.3.1. Idee von Quasi-Newton Verfahren</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#das-dfp-update">11.3.2. Das DFP-Update</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#das-bfgs-update">11.3.3. Das BFGS-Update</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limited-memory-bfgs">11.3.4. Limited-memory BFGS</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#zusammenfassung-der-verfahren-erster-und-zweiter-ordnung">11.4. Zusammenfassung der Verfahren erster und zweiter Ordnung</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Durch Dennis Janka
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>