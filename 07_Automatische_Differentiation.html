
<!DOCTYPE html>


<html lang="de" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>7. Automatische Differentiation &#8212; Optimierungsverfahren, Modellierung und Simulation (DSCB410)</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="_static/documentation_options.js?v=91fba89f"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="_static/translations.js?v=70a09b52"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"N": "\\mathbb{N}", "Z": "\\mathbb{Z}", "R": "\\mathbb{R}", "B": "\\mathbb{B}", "I": "\\mathbb{I}", "norm": ["\\left\\lVert#1 \\right\\rVert", 1], "floor": ["\\lfloor#1\\rfloor", 1], "bmat": ["\\begin{pmatrix}"], "emat": ["\\end{pmatrix}"], "bmats": ["\\left(\\begin{smallmatrix}"], "emats": ["\\end{smallmatrix}\\right)"], "scikit": ["\\texttt{scikit-learn}"], "derv": ["\\frac{\\partial #1}{\\partial #2}", 2], "dervquad": ["\\frac{\\partial^2 #1}{\\partial #2^2}", 2], "dervzwei": ["\\frac{\\partial^2 #1}{\\partial {#2} \\partial {#3}}", 3], "v": ["\\mathbf{#1}", 1], "m": ["\\mathbf{#1}", 1], "argmin": ["\\underset{#1}{\\operatorname{arg\\!min}}", 1], "hyper": ["{\\color{Bittersweet}{#1}}", 1], "initial": "\\DeclareMathOperator{\\initial}{initial}", "reduced": "\\DeclareMathOperator{\\reduced}{reduced}", "lazy": "\\DeclareMathOperator{\\lazy}{lazy}", "ILP": "\\DeclareMathOperator{\\ILP}{ILP}", "red": ["{\\color{BrickRed}{#1}}", 1]}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '07_Automatische_Differentiation';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Stichwortverzeichnis" href="genindex.html" />
    <link rel="search" title="Suche" href="search.html" />
    <link rel="next" title="8. Grundlagen der nichtlinearen Optimierung" href="08_Theoretische_Grundlagen.html" />
    <link rel="prev" title="6. Funktionen und Ableitungen" href="06_Multivariate_Analysis.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="de"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="00_Ueberblick.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/HKA_IWI_Bildmarke-h_RGB.svg" class="logo__image only-light" alt="Optimierungsverfahren, Modellierung und Simulation (DSCB410) - Home"/>
    <script>document.write(`<img src="_static/HKA_IWI_Bildmarke-h_RGB.svg" class="logo__image only-dark" alt="Optimierungsverfahren, Modellierung und Simulation (DSCB410) - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Suche" aria-label="Suche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Suche</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="00_Ueberblick.html">
                    Überblick
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Lineare Optimierungsmodelle</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01_Grundbegriffe.html">1. Einführung und Grundbegriffe</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="02_Lineare_Probleme.html">2. Lineare Optimierung</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="02_Transportproblem.html">2.9. Anwendung: Transportproblem</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="03_Ganzzahlige_Probleme.html">3. Ganzzahlige Probleme</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="03_Standortprobleme.html">3.8. Anwendung: Standortprobleme</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_Zuordnung_AWP.html">3.9. Anwendung: Studierende auf Projekte verteilen</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="04_Dynamische_Probleme.html">4. Zeitabhängige Probleme</a></li>
<li class="toctree-l1"><a class="reference internal" href="05_Praxisaspekte.html">5. Praxisaspekte beim Lösen von gemischt-ganzzahligen Programmen</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Ableitungsbasierte Optimierung</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="06_Multivariate_Analysis.html">6. Funktionen und Ableitungen</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">7. Automatische Differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="08_Theoretische_Grundlagen.html">8. Grundlagen der nichtlinearen Optimierung</a></li>
<li class="toctree-l1"><a class="reference internal" href="09_Quadratische_Probleme.html">9. Quadratische Probleme</a></li>
<li class="toctree-l1"><a class="reference internal" href="10_Gradientenverfahren.html">10. Verfahren erster Ordnung</a></li>
<li class="toctree-l1"><a class="reference internal" href="11_Verfahren_zweiter_Ordnung.html">11. Verfahren zweiter Ordnung</a></li>
<li class="toctree-l1"><a class="reference internal" href="12_Stochastischer_Gradientenabstieg.html">12. Stochastischer Gradientenabstieg</a></li>
<li class="toctree-l1"><a class="reference internal" href="13_Training_NN.html">13. Training von Neuronalen Netzen</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Laden Sie diese Seite herunter">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/07_Automatische_Differentiation.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Quelldatei herunterladen"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="In PDF drucken"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Vollbildmodus"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Suche" aria-label="Suche" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Automatische Differentiation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Inhalt </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vorbetrachtung-mathematische-funktionen-in-python">7.1. Vorbetrachtung: Mathematische Funktionen in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#berechnungsgraphen">7.2. Berechnungsgraphen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kettenregel-und-berechnunsgraphen">7.3. Kettenregel und Berechnunsgraphen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ruckwartsmodus-der-automatischen-differentiation-backpropagation">7.4. Rückwärtsmodus der automatischen Differentiation (Backpropagation)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#das-autograd-paket">7.5. Das <code class="docutils literal notranslate"><span class="pre">autograd</span></code> Paket</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="automatische-differentiation">
<span id="sec-ad"></span><h1><span class="section-number">7. </span>Automatische Differentiation<a class="headerlink" href="#automatische-differentiation" title="Link to this heading">#</a></h1>
<p>Wie wir im Kapitel <a class="reference internal" href="06_Multivariate_Analysis.html#sec-analysis"><span class="std std-ref">Funktionen und Ableitungen</span></a> gelernt haben, kann man die partiellen Ableitungen zu einer gegebenen Funktion mit einer Handvoll einfacher Regeln bestimmen. Dieses Vorgehen hat allerdings Grenzen: In vielen Anwendungen, z.B. im Bereich maschinelles Lernen, trifft man auf sehr hochdimensionale, verschachtelte Funktionen. So sind beispielsweise neuronale Netze genau das: hochdimensionale, verschachtelte Funktionen. Obwohl es theoretisch mit den herkömmlichen Ableitungsregeln möglich wäre, bestimmt natürlich niemand deren partielle Ableitung mit Papier und Bleistift, da es zum Einen viel zu lange dauern würde und sehr fehleranfällig wäre.</p>
<p>Wir schauen uns in diesem Kapitel an, wie Computer partielle Ableitungen automatisch, exakt und effizient berechnen. Wir tun dies hier teilweise anhand von entsprechenden Python Bibliotheken, weisen aber darauf hin, dass es die Verfahren auch in anderen Programmiersprachen gibt und diese dort nach den gleichen Prinzipien funktionieren.</p>
<section id="vorbetrachtung-mathematische-funktionen-in-python">
<h2><span class="section-number">7.1. </span>Vorbetrachtung: Mathematische Funktionen in Python<a class="headerlink" href="#vorbetrachtung-mathematische-funktionen-in-python" title="Link to this heading">#</a></h2>
<p>Wir schauen uns zunächst einmal an, wie Python (und die meisten anderen Programmiersprachen) mit mathematischen Funktionen, also Objekten der Art <span class="math notranslate nohighlight">\(f:\R^n\rightarrow \R\)</span>, arbeitet. Nehmen wir einmal an, wir möchten die univariate Funktion <span class="math notranslate nohighlight">\(f(x)=x^2-3x\)</span> in Python darstellen. Dies könnten wir mit folgendem Code tun:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span> <span class="o">-</span> <span class="mi">3</span><span class="o">*</span><span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<p>Nun möchten wir die Funktion plotten, z.B. im Bereich <span class="math notranslate nohighlight">\(x\in[-2,4]\)</span>. Der Computer geht dabei genauso vor, wie Sie vorgehen würden, wenn Sie die Funktion auf ein Blatt Papier zeichnen würden: Wir nehmen einige <span class="math notranslate nohighlight">\(x\)</span>-Werte aus dem gewünschten Intervall, berechnen für jeden <span class="math notranslate nohighlight">\(x\)</span>-Wert den zugehörigen Funktionswert <span class="math notranslate nohighlight">\(x^2-3x\)</span>, tragen die Punkte in ein Koordinatensystem ein und verbinden sie dann. In Python:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Erzeuge 50 äquidistante x-Werte</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">50</span><span class="p">)</span>

<span class="c1"># Berechne für jeden x-Wert den Funktionswert</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Zeichne ein Liniendiagramm für die beiden &quot;Wertelisten&quot; x und y</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Axes: &gt;
</pre></div>
</div>
<img alt="_images/5acf18b603e21e3ec069760d230ff93503b5ee22576383c1a90ae07bb6444a00.png" src="_images/5acf18b603e21e3ec069760d230ff93503b5ee22576383c1a90ae07bb6444a00.png" />
</div>
</div>
<p>Wie erwartet wird eine Parabel geplottet. Schauen wir uns aber genauer an, wie der Code eigentlich funktioniert: die Python-Funktion <code class="docutils literal notranslate"><span class="pre">f</span></code> “weiß” nicht, welcher Datentyp <code class="docutils literal notranslate"><span class="pre">x</span></code> ist. Falls <code class="docutils literal notranslate"><span class="pre">x</span></code> eine Zahl ist, liefert <code class="docutils literal notranslate"><span class="pre">f</span></code> auch nur eine Zahl zurück. Ist <code class="docutils literal notranslate"><span class="pre">x</span></code> aber ein NumPy Array, so wie hier, wird die Operation <code class="docutils literal notranslate"><span class="pre">x*x</span> <span class="pre">-</span> <span class="pre">3*x</span></code> punktweise für jedes Element des Arrays ausgeführt (dies ist durch die Definition der Operatoren <code class="docutils literal notranslate"><span class="pre">*</span></code> und <code class="docutils literal notranslate"><span class="pre">+</span></code> für NumPy Arrays so festgelegt). Konsequenterweise liefert <code class="docutils literal notranslate"><span class="pre">f</span></code> in diesem Fall auch einen Array mit Funktionswerten zurück, der die gleiche Länge hat wie der Array <code class="docutils literal notranslate"><span class="pre">x</span></code> (hier: 50). Der Funktion <code class="docutils literal notranslate"><span class="pre">sns.lineplot</span></code> werden nun die beiden Arrays, d.h. einfach Listen mit Zahlen, übergeben, die diese dann in einem Koordinatensystem einzeichnet und mit Linien verbindet. Werden dabei genügend Punkte verwendet, so ist diese eigentlich stückweise lineare Funktion nicht mehr von einer Parabel zu unterscheiden. Probieren Sie einmal aus, was passiert, wenn <code class="docutils literal notranslate"><span class="pre">x</span></code> nur aus 5 Werten besteht. Interessant daran ist, dass <code class="docutils literal notranslate"><span class="pre">sns.lineplot</span></code> gar nicht “weiß”, dass es sich um die Funktion <span class="math notranslate nohighlight">\(f(x)=x^2-3x\)</span> handelt. Es bekommt lediglich Listen mit Zahlen übergeben.</p>
<p>Dieses Paradigma des punktweisen Auswertens wird auch bei der automatischen Berechnung von Ableitungen verfolgt. Anstatt den algebraischen Ausdruck <span class="math notranslate nohighlight">\(x^2-3x\)</span> bzw. dessen Code-Repräsentation <code class="docutils literal notranslate"><span class="pre">x*x</span> <span class="pre">-</span> <span class="pre">3*x</span></code> umzuformen, so wie wir es tun würden, wenn wir per Hand die Ableitung berechnen, wird mittels eines speziellen Algorithmus sichergestellt, dass bei einer punktweisen Auswertung von <code class="docutils literal notranslate"><span class="pre">f</span></code> auch deren Ableitung an diesem Punkt ausgewertet wird.</p>
</section>
<section id="berechnungsgraphen">
<h2><span class="section-number">7.2. </span>Berechnungsgraphen<a class="headerlink" href="#berechnungsgraphen" title="Link to this heading">#</a></h2>
<p>Um Ableitungen automatisch auszuwerten, wird jede mathematische Funktion als ein <em>gerichteter, azyklischer Graph</em> aufgefasst. Dies ist eine Menge aus Knoten und Kanten, die keine Kreise enthält.</p>
<figure class="align-default" id="id3">
<a class="reference internal image-reference" href="_images/graphen.png"><img alt="_images/graphen.png" src="_images/graphen.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Abb. 7.1 </span><span class="caption-text">Links: Gerichtetet, azyklischer Graph. Mitte: Ungerichteter azyklischer Graph. Rechts: Gerichteter Graph mit Zyklus.</span><a class="headerlink" href="#id3" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Wenn eine Kante von Knoten a nach Knoten b existiert, so nennt man a auch ein <em>Kind</em> von b. Wir nennen außerdem Knoten, zu denen keine Kante hinführt, <em>Eingangsknoten</em>, und Knoten, von denen keine Kante wegführt, <em>Ausgangsknoten</em>.</p>
<div class="proof observation admonition" id="observation-0">
<p class="admonition-title"><span class="caption-number">Observation 7.1 </span></p>
<section class="observation-content" id="proof-content">
<p>Jede in Quellcode implementierte mathematische Funktion kann als <em>Abfolge elementarer Operationen</em> aufgefasst werden und in einem gerichteten, azyklischen Graphen dargestellt werden. Unter dem Begriff “elementare Operationen” stellen wir uns zunächst die Operationen <span class="math notranslate nohighlight">\(+, -, \cdot, /\)</span> sowie die mathematischen Funktionen <span class="math notranslate nohighlight">\(\exp, \sin, \cos, \ln\)</span> vor. Später werden wir sehen, dass es hilfreich ist auch andere Operationen als “elementare Operation” zu definieren, insbesondere vektorwertige.</p>
</section>
</div><div class="proof example admonition" id="example-1">
<p class="admonition-title"><span class="caption-number">Example 7.1 </span></p>
<section class="example-content" id="proof-content">
<p>Die Funktion</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
f(x)=(x_1x_2\sin x_3 + e^{x_1x_2})/x_3
\end{align*}\]</div>
<p>kann als folgende Abfolge elementarer Operationen aufgefasst werden:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
x_4&amp;=x_1\cdot x_2\\
x_5&amp;=\sin x_3\\
x_6&amp;=e^{x_4}\\
x_7&amp;=x_4\cdot x_5\\
x_8&amp;=x_6+x_7\\
x_9&amp;=x_8/x_3
\end{align*}\]</div>
<p>In jeder Zeile wird genau <em>eine</em> elementare Operation ausgeführt. Die Reihenfolge, in der die Operationen ausgeführt werden, ist dabei nicht immer eindeutig. Die Variablen <span class="math notranslate nohighlight">\(x_4,\dots,x_9\)</span> sind <em>Zwischenvariablen</em> (im Gegensatz zu den <em>unabhängigen</em> Variablen <span class="math notranslate nohighlight">\(x_1,x_2,x_3\)</span>) und ergeben sich für beliebige Werte <span class="math notranslate nohighlight">\(x_1,x_2,x_3\)</span>. <span class="math notranslate nohighlight">\(x_9\)</span> enthält den Funktionswert.</p>
<p>Als Graph lässt sich das Ganze wie folgt darstellen:</p>
<figure class="align-default">
<a class="reference internal image-reference" href="_images/berechnungsgraph.png"><img alt="_images/berechnungsgraph.png" src="_images/berechnungsgraph.png" style="width: 500px;" /></a>
</figure>
</section>
</div><p>Die Zwischenvariablen <span class="math notranslate nohighlight">\(x_4,\dots,x_9\)</span> müssen übrigens nicht explizit als Variablen im Code eingeführt werden. Sie repräsentieren vielmehr die logische Abfolge der Berechnungsschritte. Tools zur automatischen Ableitungserzeugung erzeugen diesen Berechnungsgraphen automatisch (z.B. PyTorch, Tensorflow, autograd).</p>
</section>
<section id="kettenregel-und-berechnunsgraphen">
<h2><span class="section-number">7.3. </span>Kettenregel und Berechnunsgraphen<a class="headerlink" href="#kettenregel-und-berechnunsgraphen" title="Link to this heading">#</a></h2>
<p>Das Konzept von Berechnungsgraphen ist (hoffentlich) illustrativ und verständlich. Wir werden nun sehen, dass die Darstellung einer Funktion als Berechnungsgraph der Schlüssel dafür ist, automatisch ihre partielle Ableitungen auszuwerten. Dazu halten wir als nächsten Schritt folgendes fest:</p>
<div class="proof observation admonition" id="observation-2">
<p class="admonition-title"><span class="caption-number">Observation 7.2 </span></p>
<section class="observation-content" id="proof-content">
<p>Berechnungsgraphen beschreiben die <em>Verkettung</em> von Funktionen, und zwar derjenigen Funktionen, die durch die elementaren Operationen definiert sind.</p>
</section>
</div><p>Wie schauen uns dazu ein einfaches Beispiel an. Die Funktion <span class="math notranslate nohighlight">\(h(x)=\cos x^2\)</span> kann als verkettete Funktion der beiden Funktionen <span class="math notranslate nohighlight">\(g(y)=\cos y\)</span> und <span class="math notranslate nohighlight">\(f(x)=x^2\)</span> aufgefasst werden:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
h(x)=g(f(x))=\cos x^2
\end{align*}\]</div>
<p>Erinnerung: das hatten wir in den Abschnitten <a class="reference internal" href="06_Multivariate_Analysis.html#sec-stetigkeit"><span class="std std-ref">Stetigkeit multivariater Funktionen</span></a> und <a class="reference internal" href="06_Multivariate_Analysis.html#sec-kettenregel"><span class="std std-ref">Die Kettenregel</span></a> mit <span class="math notranslate nohighlight">\(g\circ f\)</span> (erst <span class="math notranslate nohighlight">\(f\)</span>, dann <span class="math notranslate nohighlight">\(g\)</span>) bezeichnet.</p>
<p>Der Berechnungsgraph zur Funktion <span class="math notranslate nohighlight">\(h(x)=\cos x^2\)</span> ist</p>
<figure class="align-default" id="fig-simplegraph">
<a class="reference internal image-reference" href="_images/berechnungsgraph2.png"><img alt="_images/berechnungsgraph2.png" src="_images/berechnungsgraph2.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Abb. 7.2 </span><span class="caption-text">Ein einfacher Berechnungsgraph.</span><a class="headerlink" href="#fig-simplegraph" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Der Graph beschreibt also gerade die Verkettung <span class="math notranslate nohighlight">\(g(f(x))\)</span>. Dies ist auch nicht nur in diesem einfachen univariaten Beispiel so, sondern gilt allgemein für Berechnungsgraphen. Um nun die Ableitung dieses Berechnungsgraphen zu berechnen, der die <em>Verkettung</em> von Funktionen darstellt, benutzt man die … Kettenregel!</p>
<p>Wir schauen uns nun an, wie die Kettenregel für Berechnungsgraphen funktioniert. Dafür berechnen wir zunächst die Ableitung der Funktion <span class="math notranslate nohighlight">\(h\)</span> mit der gewöhnlichen Kettenregel:<a class="footnote-reference brackets" href="#kettenregel" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\derv{h}{x}=\derv{g(f(x))}{x}=\underbrace{\derv{g(f(x))}{f(x)}}_{-\sin{f(x)}}\cdot\underbrace{\derv{f}{x}}_{2x}=-2x\cdot \sin{x^2}
\end{align*}\]</div>
<p>Dies entspricht der bekannten Merkregel “Äußere Ableitung <span class="math notranslate nohighlight">\(\times\)</span> innere Ableitung”. In dem zugehörigen Berechnungsgraphen lässt sich die Kettenregel wie folgt interpretieren:</p>
<div class="proof observation admonition" id="obs:pfad">
<p class="admonition-title"><span class="caption-number">Observation 7.3 </span> (Ableitung entlang eines Pfads)</p>
<section class="observation-content" id="proof-content">
<p>Annotiere jeden Knoten mit seiner Ableitung bezüglich des Inputs (d.h. die Ableitung einer der “elementaren Operationen”) und multipliziere die Knoten entlang des Pfades.</p>
</section>
</div><p>Nun haben Berechnungsgraphen im Allgemeinen eine kompliziertere Gestalt als <a class="reference internal" href="#fig-simplegraph"><span class="std std-numref">Abb. 7.2</span></a>. Wie lässt sich die Pfadregel verallgemeinern? Wir betrachten dazu das (immer noch univariate) Beispiel <span class="math notranslate nohighlight">\(f(x)=\sin x^2 + \cos x^2\)</span>. Der Berechnungsgraph von <span class="math notranslate nohighlight">\(f\)</span> ist:<a class="footnote-reference brackets" href="#argumente" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a></p>
<figure class="align-default" id="fig-example-graph">
<a class="reference internal image-reference" href="_images/berechnungsgraph3.png"><img alt="_images/berechnungsgraph3.png" src="_images/berechnungsgraph3.png" style="width: 600px;" /></a>
</figure>
<p>Interessant ist, dass wir, um die Funktion <span class="math notranslate nohighlight">\(f\)</span> wirklich als Berechnungsgraph und damit als Verkettung von Funktionen zu schreiben, auf mehrdimensionale Funktionen zurückgreifen müssen. Die <span class="math notranslate nohighlight">\(+\)</span>-Operation wird nämlich durch die Funktion <span class="math notranslate nohighlight">\(k:\R^2\rightarrow\R\)</span> mit <span class="math notranslate nohighlight">\(k(v,w)=v+w\)</span> dargestellt.</p>
<p>Wir berechnen nun für diese Verkettung die partielle Ableitung mit der multivariaten Kettenregel (das ist der schwierige Teil) und schauen dann, wie sie sich in dem Graph interpretieren lässt (das ist der einfache Teil). Es gilt:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
f(x)&amp;=k(v,w)=k(h(y),i(z))=k(h(g(x)),i(g(x)))\\
\derv{f}{x}&amp;=\left(\derv{k(v,w)}{v},\derv{k(v,w)}{w}\right)\cdot \bmat \derv{h(y)}{y}\\\derv{i(z)}{z} \emat\cdot\derv{g}{x}\\
%\derv{f}{x}&amp;=\derv{k(h(g(x)),i(g(x)))}{h(g(x)),i(g(x))}\cdot \bmat \derv{h(g(x))}{g(x)}\\\derv{i(g(x))}{g(x)} \emat\cdot  \derv{g}{x}\\
&amp;=\bmat 1, &amp; 1 \emat \cdot\bmat cos y \\ -\sin z \emat \cdot 2x\\
&amp;=(\cos y-\sin z)2x \\
&amp;= 2x\cdot \cos x^2 - 2x\cdot \sin x^2
\end{align*}\]</div>
<p>Während es bei der Anwendung der multivariaten Kettenregel oft schwerfällt, den Überblick über die Symbole und Dimensionen zu behalten, ist ihre Interpretation auf Berechnungsgraphen sehr einfach: Es gibt in dem Graphen zwei Pfade von <span class="math notranslate nohighlight">\(x\)</span> nach <span class="math notranslate nohighlight">\(f\)</span>. Die Ableitung von <span class="math notranslate nohighlight">\(f\)</span> nach <span class="math notranslate nohighlight">\(x\)</span> ist die Summe der Ableitungen entlang der beiden Pfade. Entlang jedes Pfads wird die Ableitung gemäß
<a class="reference internal" href="#obs:pfad">Observation 7.3</a> berechnet. Wir halten diese Beobachtung in folgendem Satz fest:</p>
<div class="proof theorem admonition" id="thm:kettenregel_pfad">
<p class="admonition-title"><span class="caption-number">Theorem 7.1 </span></p>
<section class="theorem-content" id="proof-content">
<p>Sei <span class="math notranslate nohighlight">\(f:\R^n\rightarrow\R\)</span> eine differenzierbare Funktion, die durch einen Berechnungsgraphen mit Eingangsknoten <span class="math notranslate nohighlight">\(x_1,x_2,\dots,x_n\)</span> und Ausgangsknoten <span class="math notranslate nohighlight">\(f\)</span> repräsentiert wird. Dann kann man die Ableitung <span class="math notranslate nohighlight">\(\derv{f}{\v x}\)</span> mittels der multivariaten Kettenregel auf dem Berechnungsgraphen wie folgt interpretieren:
Die Ableitung der Variable im Output Knoten <span class="math notranslate nohighlight">\(f\)</span> nach einer Variable in einem Eingangsknoten <span class="math notranslate nohighlight">\(x_i\)</span> ist die Summe der Ableitungen entlang aller möglichen Pfade zwischen <span class="math notranslate nohighlight">\(x_i\)</span> und <span class="math notranslate nohighlight">\(f\)</span>. Die Ableitungen entlang der Pfade können mit der unvariaten Kettenregel als Produkte der (lokalen) Ableitungen an jedem Knoten des Pfads berechnet werden.</p>
</section>
</div><p>Wir haben das Problem der Ableitungsberechnung nun also auf ein Problem auf Berechnungsgraphen zurückgeführt. Die Anzahl der möglichen Pfade zwischen Eingangs- und Ausgangsknoten wächst allerdings exponentiell, wie wir anhand des folgenden Beispiels sehen können.</p>
<p>Das Problem der vielen Pfade äußert sich dadurch, dass mehrfach die gleichen Berechnungen durchgeführt werden. In dem Beispiel liegt jeder Zwischenknoten auf 16 Pfaden, es würde also 16 Mal exakt die gleiche Berechnung durchgeführt.</p>
</section>
<section id="ruckwartsmodus-der-automatischen-differentiation-backpropagation">
<h2><span class="section-number">7.4. </span>Rückwärtsmodus der automatischen Differentiation (Backpropagation)<a class="headerlink" href="#ruckwartsmodus-der-automatischen-differentiation-backpropagation" title="Link to this heading">#</a></h2>
<p>Ein Ansatz, der die Iteration über alle möglichen Pfade vermeidet, ist der <a class="reference external" href="https://de.wikipedia.org/wiki/Dynamische_Programmierung">dynamischen Programmierung</a> entlehnt. Hierbei werden Ergebnisse (Ableitungen) zwischengespeichert und an geeigneter Stelle wiederverwendet. Damit das funktioniert, müssen die Knoten in einer bestimmten Reihenfolge durchlaufen werden. Als Konsequenz, wird im Laufe des Verfahrens jeder Knoten und jede Kante des Graphen genau zweimal bearbeitet, das Verfahren unterliegt also keinem exponentiellen Wachstum.</p>
<p>Das Verfahren ist – vor allem für den Bereich maschinelles Lernen – einer der bekanntesten und wichtigsten mathematischen Algorithmen überhaupt und ist vor allem unter zwei Namen bekannt:</p>
<ol class="arabic simple">
<li><p>Rückwärtsmodus der automatischen Differentiation</p></li>
<li><p>Backpropagation (of errors)</p></li>
</ol>
<p>Es ist nicht übertrieben zu sagen, dass alle aktuellen Entwicklungen im Bereich KI ohne dieses Verfahren nicht existieren würden. Es wurde im Laufe der Jahre von <a class="reference external" href="https://people.maths.ox.ac.uk/~trefethen/inventorstalk.pdf">verschiedenen Forschern</a>  (wieder-)entdeckt. Die erste allgemeine Form geht auf den finnischen Mathematiker Seppo Linnainmaa zurück, der das Verfahren 1970 in seiner Masterarbeit entwickelte.</p>
<p>Der Algorithmus arbeitet auf einem Berechnungsgraphen einer Funktion <span class="math notranslate nohighlight">\(f:\R^n\rightarrow\R\)</span>, dessen Knoten wir mit <span class="math notranslate nohighlight">\(x_1,\dots,x_N\)</span> bezeichnen. Dabei seien die ersten <span class="math notranslate nohighlight">\(n\)</span> Knoten <span class="math notranslate nohighlight">\(x_1,\dots,x_n\)</span> die Eingangsknoten und der letzte Knoten <span class="math notranslate nohighlight">\(x_N=f(\v x)\)</span> der Ausgangsknoten. Der Algorithmus arbeitet in zwei Phasen:</p>
<ol class="arabic simple">
<li><p>Vorwärtsphase: Für einen gegebenen (beliebigen) Wert der Eingangsknoten <span class="math notranslate nohighlight">\(\v x'=(x_1',\dots,x_n')\)</span> wird der Wert an allen Knoten <span class="math notranslate nohighlight">\(x_{n+1}',\dots,x_N'=f(\v x')\)</span> bestimmt.</p></li>
<li><p>Rückwärtsphase: Hier wird der Graph rückwärts, d.h. ausgehend vom Ausgangsknoten traversiert. Dabei werden alle partiellen Ableitungen <span class="math notranslate nohighlight">\(\derv{f}{x_i}(\v x'), i=1,\dots,N\)</span> bestimmt.</p></li>
</ol>
<p>Eigentlich möchten wir ja nur die Ableitung nach den Eingangsknoten, d.h. <span class="math notranslate nohighlight">\(\derv{f}{x_i}(\v x'), i=1,\dots,n\)</span>, aber durch die Art wie der Algorithmus arbeitet, bekommen wir die anderen Ableitungen gratis dazu. Wir führen für die partiellen Ableitungen die folgenden Bezeichner ein:</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*} 
\overline{x}_i:=\derv{f}{x_i}(\v x')
\end{align*}\]</div>
<p>Die Variablen <span class="math notranslate nohighlight">\(\overline{x}_i\)</span> nennt man auch <em>adjungierte Variablen</em>. Diese werden im Verlauf des Algorithmus nach und nach berechnet. Damit können wir den Algorithmus wie folgt spezifizieren:</p>
<div class="proof algorithm admonition" id="alg:backprop">
<p class="admonition-title"><span class="caption-number">Algorithm 7.1 </span> (Rückwärtsmodus der automatischen Differentiation (Backpropagation))</p>
<section class="algorithm-content" id="proof-content">
<dl class="simple myst">
<dt>Gegeben:</dt><dd><ul class="simple">
<li><p>Gerichteter, azyklischer Berechnungsgraph mit Knoten <span class="math notranslate nohighlight">\(x_i, i=1,\dots,N\)</span>, wobei <span class="math notranslate nohighlight">\(x_N=f\)</span> die Variable im Ausgangsknoten sei (die Funktion, deren Ableitung berechnet werden soll)</p></li>
</ul>
</dd>
<dd><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\v x'=(x_1',\dots,x_n')\)</span>: Werte an den Eingangsknoten (die Stelle, an denen die Ableitung von <span class="math notranslate nohighlight">\(f\)</span> ausgewertet werden soll)</p></li>
</ul>
</dd>
<dd><ul class="simple">
<li><p>Für jedes Kind <span class="math notranslate nohighlight">\(j\)</span> des Knoten <span class="math notranslate nohighlight">\(i\)</span> bezeichne <span class="math notranslate nohighlight">\(\derv{x_i}{x_j}\)</span> die („lokale“) Ableitung (=“wie ändert sich <span class="math notranslate nohighlight">\(x_j\)</span>, wenn sich <span class="math notranslate nohighlight">\(x_i\)</span> ändert, unabhängig davon was vor <span class="math notranslate nohighlight">\(i\)</span> und nach <span class="math notranslate nohighlight">\(j\)</span> geschieht”)</p></li>
</ul>
</dd>
<dt>Gesucht:</dt><dd><ul class="simple">
<li><p>Werte an allen Knoten <span class="math notranslate nohighlight">\(x_i'\)</span>, insbesondere der Wert am Ausgangsknoten <span class="math notranslate nohighlight">\(x_N'=f(\v x')\)</span></p></li>
</ul>
</dd>
<dd><ul class="simple">
<li><p>Alle partiellen Ableitungen <span class="math notranslate nohighlight">\(\derv{f}{x_i}(\v x')\)</span>, insbesondere die Ableitungen nach den Eingangsknoten <span class="math notranslate nohighlight">\(\derv{f}{\v x}(\v x')\)</span></p></li>
</ul>
</dd>
</dl>
<p><strong>Algorithmus</strong>:</p>
<ol class="arabic">
<li><p>Start: Initialisiere <span class="math notranslate nohighlight">\(\overline{x}_N=\derv{f}{f}=1\)</span>.</p></li>
<li><p>Solange noch Knoten vorhanden sind, die noch nicht ausgewählt wurden:</p>
<ol class="arabic simple">
<li><p>Wähle unbearbeiteten Knoten <span class="math notranslate nohighlight">\(i\)</span>, von dem alle Werte <span class="math notranslate nohighlight">\(\overline{x}_j\)</span> der Kinder bekannt sind.</p></li>
<li><p>Setze</p></li>
</ol>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
     \overline{x}_i=\sum_{j: \textup{Kind von }i} \overline{x}_j\cdot \derv{x_j}{x_i}=\sum_{j: \textup{Kind von }i} \derv{f}{x_j}\cdot  \derv{x_j}{x_i}
     \end{align*}\]</div>
</li>
</ol>
</section>
</div><p>Wie Sie sehen, ist der Algorithmus selbst relativ kurz. Die Formel zur Berechnung von <span class="math notranslate nohighlight">\(\overline{x}_i\)</span> ist übrigens gerade die Kettenregel: Die Ableitung von <span class="math notranslate nohighlight">\(f\)</span> nach <span class="math notranslate nohighlight">\(x_i\)</span> ist die Ableitung von <span class="math notranslate nohighlight">\(f\)</span> bis zu den Knoten, die unmittelbar nach <span class="math notranslate nohighlight">\(x_i\)</span> kommen multipliziert mit der lokalen Ableitung <span class="math notranslate nohighlight">\(\derv{x_j}{x_i}\)</span>.</p>
<p>Wir führen den Algorithmus noch einmal am Beispiel von weiter oben, <span class="math notranslate nohighlight">\(f(x)=\sin x^2 + \cos x^2\)</span> aus. Dabei verwenden wir die Notation der Zwischenknoten mit <span class="math notranslate nohighlight">\(x_i\)</span> und notieren auch gleich die Adjungierten <span class="math notranslate nohighlight">\(\overline{x}_i\)</span> an jeden Knoten.</p>
<figure class="align-default" id="fig-example-graph-x">
<a class="reference internal image-reference" href="_images/berechnungsgraph3.png"><img alt="_images/berechnungsgraph3.png" src="_images/berechnungsgraph3.png" style="width: 600px;" /></a>
</figure>
<div class="proof example admonition" id="example-6">
<p class="admonition-title"><span class="caption-number">Example 7.2 </span> (Backpropagation für <span class="math notranslate nohighlight">\(f(x)=\sin x^2+\cos^2\)</span> an der Stelle <span class="math notranslate nohighlight">\(x=\sqrt{\pi}\)</span>)</p>
<section class="example-content" id="proof-content">
<p>Vorwärtsphase:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_1=\sqrt{\pi}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x_2=x_1^2=\pi\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x_3=\sin x_2=0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x_4=\cos x_2=-1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x_5=x_3+x_4\)</span></p></li>
</ul>
<p>Rückwärtsphase:</p>
<ul class="simple">
<li><p>Schritt 1: Start: Setze <span class="math notranslate nohighlight">\(\overline{x}_5=\derv{f}{f}=1\)</span>
Als nächstes müssen wir einen unbearbeiteten Knoten wählen, dessen Kinder bereits berechnet wurden. Wir können entweder <span class="math notranslate nohighlight">\(x_4\)</span> oder <span class="math notranslate nohighlight">\(x_3\)</span> wählen.</p></li>
<li><p>Schritt 2: Wähle <span class="math notranslate nohighlight">\(x_4\)</span>. Setze <span class="math notranslate nohighlight">\(\overline{x}_4=\overline{x}_5\derv{x_5}{x_4}=1\cdot1=1\)</span>.
Der Ausdruck <span class="math notranslate nohighlight">\(\derv{x_5}{x_4}\)</span> sieht etwas ungewohnt aus. Stellen sie sich dafür <span class="math notranslate nohighlight">\(x_5\)</span> als <em>Funktion</em> vor, die abgeleitet wird. Als nächstes müssen wir <span class="math notranslate nohighlight">\(x_3\)</span> wählen.</p></li>
<li><p>Schritt 3: Wähle <span class="math notranslate nohighlight">\(x_3\)</span>. Setze <span class="math notranslate nohighlight">\(\overline{x}_3=\overline{x}_5\derv{x_5}{x_3}=1\cdot1=1\)</span>.
Nun können wir <span class="math notranslate nohighlight">\(x_2\)</span> wählen. <span class="math notranslate nohighlight">\(x_2\)</span> hat zwei Kinder, also müssen auch zwei lokale Ableitungen aufsummiert werden.</p></li>
<li><p>Schritt 4: Wähle <span class="math notranslate nohighlight">\(x_2\)</span>. Setze <span class="math notranslate nohighlight">\(\overline{x}_2=\overline{x}_4\derv{x_4}{x_2}+\overline{x}_3\derv{x_3}{x_2}=1\cdot(-sin x_2)+1\cdot\cos x_2=-1\)</span>.</p></li>
<li><p>Schritt 5: Wähle <span class="math notranslate nohighlight">\(x_1\)</span>. Setze <span class="math notranslate nohighlight">\(\overline{x}_1=\overline{x}_2\derv{x_2}{x_1}=-1\cdot2x_1=-2\sqrt{\pi}\)</span></p></li>
</ul>
<p>Damit sind alle Knoten bearbeitet und der Algorithmus terminiert. Der Funktionswert von <span class="math notranslate nohighlight">\(f\)</span> an der Stelle <span class="math notranslate nohighlight">\(\sqrt{\pi}\)</span> ist <span class="math notranslate nohighlight">\(f(\sqrt{\pi})=-1\)</span>, die Ableitung ist <span class="math notranslate nohighlight">\(\overline{x}_1=\derv{f}{x}=-2\sqrt{\pi}\)</span>.</p>
</section>
</div><p>Der Backpropagation Algorithmus erlaubt es, Ableitungen beliebig komplizierter Funktion mittels einem einfach Schema effizient zu berechnen. Dafür müssen die Ableitungen der elementaren Operationen, aus denen der Berechnungsgraph aufgebaut ist, einmalig fest hinterlegt werden. Weiterhin muss bei der Vorwärtsphase jeder Wert <span class="math notranslate nohighlight">\(x_1,\dots,x_N\)</span> zwischengespeichert werden, damit er bei der Rückwärtsphase zur Verfügung steht. Der dafür benötigte Speicherplatz kann bei großen Funktionen (neuronalen Netzen), wie sie z.B. im Bereich maschinelles Lernen und KI vorkommen, signifikant sein.</p>
</section>
<section id="das-autograd-paket">
<h2><span class="section-number">7.5. </span>Das <code class="docutils literal notranslate"><span class="pre">autograd</span></code> Paket<a class="headerlink" href="#das-autograd-paket" title="Link to this heading">#</a></h2>
<p>Im Paket <code class="docutils literal notranslate"><span class="pre">autograd</span></code> ist der Rückwärtsmodus der automatischen Differentiation implementiert. Es ist sehr benutzerfreundlich. Sie können es mittels</p>
<blockquote>
<div><p>pip install autograd</p>
</div></blockquote>
<p>aus den Python Paketquellen installieren. <code class="docutils literal notranslate"><span class="pre">autograd</span></code> baut auf NumPy auf und erweitert es um automatische Ableitungsberechnung. Wir schauen uns das Paket anhand der Beispielfunktion aus dem vorherigen Abschnitt an. Zunächst müssen wir anstatt NumPy <code class="docutils literal notranslate"><span class="pre">autograd.numpy</span></code> importieren. Dies ist ein Wrapper für die NumPy Klassen und Funktionen, d.h. es lässt sich bedienen wie NumPy, aber es wird der entsprechende Berechnungsgraph mit erzeugt. Weiterhin importieren wir die Methode grad, mit der Gradienten berechnet werden.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">autograd.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">autograd</span> <span class="kn">import</span> <span class="n">grad</span>
</pre></div>
</div>
</div>
</div>
<p>Wir definieren nun unsere Funktion <span class="math notranslate nohighlight">\(f(x)=\sin x^2 +\cos x^2\)</span> und werten sie testhalber an der Stelle <span class="math notranslate nohighlight">\(\sqrt{\pi}\)</span> aus:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span> <span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">x_0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="p">(</span><span class="n">x_0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.9999999999999994
</pre></div>
</div>
</div>
</div>
<p>Nun kommt die Ableitungsberechnung. Wir rufen die eben importierte Funktion <code class="docutils literal notranslate"><span class="pre">grad</span></code> auf und übergeben ihr unsere Funktion <code class="docutils literal notranslate"><span class="pre">f</span></code> als Argument. Das Rückgabewert ist wieder eine Funktion, nämlich eine Funktion, die den Gradienten von <code class="docutils literal notranslate"><span class="pre">f</span></code> an einer beliebigen Stelle auswertet.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grad_f</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grad_f</span><span class="p">(</span><span class="n">x_0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-3.544907701811034
</pre></div>
</div>
</div>
</div>
<p>Das funktioniert auch mit mehrdimensionalen Funktionen, z.B. <span class="math notranslate nohighlight">\(g(x,y,z)=xy^2+z(x-y)\)</span>. Der Rückgabewert ist dann ein NumPy Array (Vektor) der Länge 3.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">autograd.numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">autograd</span> <span class="kn">import</span> <span class="n">grad</span>

<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span><span class="mf">2.</span><span class="p">,</span><span class="mf">3.</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">g</span><span class="p">(</span><span class="n">x0</span><span class="p">))</span>

<span class="n">grad_g</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">grad_g</span><span class="p">(</span><span class="n">x0</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
[ 7.  1. -1.]
</pre></div>
</div>
</div>
</div>
<hr class="footnotes docutils" />
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="kettenregel" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p>Obwohl wir es hier mit einer univariaten Funktion zu tun haben, nutzen wir trotzdem die Notation für die partielle Ableitung, da der multivariate Fall analog verlaufen wird.</p>
</aside>
<aside class="footnote brackets" id="argumente" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Wir haben hier eigene Bezeichner <span class="math notranslate nohighlight">\(x,y,z,v,w\)</span> für die Argumente der Teilfunktionen eingeführt. Dies ist eigentlich nicht nötig, es soll hier nur klar gemacht werden, dass die einzelnen Knoten nichts voneinander “wissen”. D.h. jeder Knoten hat einen Eingangswert und einen Ausgangswert. Zwar können bestimmte Eingangs- bzw. Ausgangswerte identisch sein (im Beispiel wäre etwa <span class="math notranslate nohighlight">\(y=z=x^2\)</span>), das “wissen” aber die einzelnen Knoten nicht.</p>
</aside>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="06_Multivariate_Analysis.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">zurück</p>
        <p class="prev-next-title"><span class="section-number">6. </span>Funktionen und Ableitungen</p>
      </div>
    </a>
    <a class="right-next"
       href="08_Theoretische_Grundlagen.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">weiter</p>
        <p class="prev-next-title"><span class="section-number">8. </span>Grundlagen der nichtlinearen Optimierung</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Inhalt
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#vorbetrachtung-mathematische-funktionen-in-python">7.1. Vorbetrachtung: Mathematische Funktionen in Python</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#berechnungsgraphen">7.2. Berechnungsgraphen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kettenregel-und-berechnunsgraphen">7.3. Kettenregel und Berechnunsgraphen</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ruckwartsmodus-der-automatischen-differentiation-backpropagation">7.4. Rückwärtsmodus der automatischen Differentiation (Backpropagation)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#das-autograd-paket">7.5. Das <code class="docutils literal notranslate"><span class="pre">autograd</span></code> Paket</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
Durch Dennis Janka
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>