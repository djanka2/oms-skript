{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anwendung: Logistische Regression\n",
    "\n",
    "In diesem Notebook trainieren wir ein Modell, das für den Kunden einer Website vorhersagen soll, ob er oder sie ein Produkt kauft oder nicht. Grundlage für dieses Klassifikationsproblem sind demografische Daten sowie das Verhalten der Kunden. Angenommen, wir erheben für die Kunden folgende Merkmale:\n",
    "\n",
    "- Age: Alter des Kunden ($x_1$)\n",
    "- Gender: Geschlecht des Kunden, wobei 0=weiblich, 1=männlich ($x_2$)\n",
    "- Annual Income: Jahreseinkommen in tausend Euro ($x_3$)\n",
    "- Browsing Time: Verbrachte Zeit auf der Website in Minuten ($x_4$)\n",
    "- Previous Purchases: Anzahl vorheriger Käufe des Kunden ($x_5$)\n",
    "\n",
    "Wir haben von 100 Kunden folgende Daten gesammelt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Browsing Time</th>\n",
       "      <th>Previous Purchases</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender  Annual Income  Browsing Time  Previous Purchases  Purchased\n",
       "0    22       0             40              5                   0          0\n",
       "1    35       1             60             10                   3          1\n",
       "2    26       1             30              3                   1          0\n",
       "3    29       0             55              8                   2          1\n",
       "4    42       1             80             12                   4          1\n",
       "..  ...     ...            ...            ...                 ...        ...\n",
       "95   24       1             34              3                   1          0\n",
       "96   37       1             81             13                   4          1\n",
       "97   28       0             40              5                   1          0\n",
       "98   33       1             64              9                   3          1\n",
       "99   30       1             58              8                   2          0\n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Daten/purchase.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Spalte `Purchased` gibt an, ob der Kunde das Produkt gekauft hat. Im maschinellen Lernen bezeichnet man dies als Label, welches meist mit $y_i, i=1,\\dots,100$ bezeichnet wird. \n",
    "\n",
    "Wir trainieren nun ein logistisches Regressionsmodell, welches die Spalte `Purchased` möglichst gut aus den anderen vorhersagen soll. Dazu machen wir folgenden Ansatz für die Modellfunktion:\n",
    "\n",
    "\\begin{align*}\n",
    "    P(\\texttt{Purchased}) = \\sigma(\\v w^T\\v x) = \\frac{1}{1+e^{-\\v w^T \\v x}} = \\frac{1}{1+e^{-(w_1x_1 + w_2x_2 + w_3x_3 + w_4x_4 + w_5x_5)}},\n",
    "\\end{align*}\n",
    "\n",
    "Die Funktion \n",
    "\\begin{align*}\n",
    "    \\sigma(t) = \\frac{1}{1+e^{-t}}\n",
    "\\end{align*}\n",
    "ist die *logistische Funktion*. Diese stellt sicher, dass die Vorhersage zwischen $0$ und $1$ liegt und als Wahrscheinlichkeit interpretiert werden kann.\n",
    "\n",
    "Aufgabe des Modelltrainings ist es nun, diejenigen Parameter $w_1,\\dots, w_5$ zu identifizieren, so dass die vorhergesagten Wahrscheinlichkeiten $f(\\v x; \\v w)$ möglichst gut zu den echten Werten der Spalte `Purchased` passen. Für die lineare Regression misst man dies mit dem mittleren quadratischen Fehler. Dies ist eine quadratische Funktion, für die man (über die Normalengleichungen) ein globales Minimum analytisch bestimmen kann. Für die logistische Regression nimmt man stattdessen die binäre Kreuzentropie:\n",
    "\n",
    "\\begin{align*}\n",
    " L(\\v w)=-\\frac{1}{N}\\sum_{i=1}^{100} \\ln{\\left[ y_i \\cdot \\sigma(\\v w^T\\v x_i) + (1-y_i) \\cdot (1-\\sigma(\\v w^T\\v x_i))\\right]}  \n",
    "\\end{align*}\n",
    "\n",
    "Diese Funktion gilt es nun zu minimieren. Ihr Minimum kann im Gegensatz zur linearen Regression nicht mehr analytisch bestimmt werden, sondern es werden iterative Verfahren benötigt (Gradientenverfahren bzw. Newtonverfahren).\n",
    "\n",
    "Wir definieren dazu zunächst den Labelvektor $\\v y$ sowie die Designmatrix $\\v X$. Wir casten sowohl $\\v y$ und $\\v X$ explizit als `autograd.numpy` arrays, damit die `autograd` diese beim Differenzieren korrekt verarbeiten kann. Anschließend definieren wir die logistische Funktion sowie die binäre Kreuzentropie als Python Funktionen. \n",
    "\n",
    "### Gradientenverfahren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "\n",
    "# Labelvektor\n",
    "y = np.array(df.Purchased)\n",
    "\n",
    "# Designmatrix\n",
    "X = df.drop(\"Purchased\", axis=1)\n",
    "X = (X - X.mean()) / X.std()\n",
    "\n",
    "# Explizit als autograd numpy array casten\n",
    "X = np.array(X)\n",
    "\n",
    "# Logistische Funktion\n",
    "def logistic(x, w):\n",
    "    return 1.0 / (1 + np.exp(-x@w))\n",
    "\n",
    "# Binäre Kreuzentropie\n",
    "def binary_cross_entropy(w):\n",
    "    \n",
    "    y_pred = logistic(X,w)\n",
    "\n",
    "    return -np.sum(np.log(y*y_pred + (1-y)*(1-y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir benutzen ein Gradientenverfahren mit fester Schrittweite um die optimalen Parameter zu berechnen. Dank `autograd` müssen wir uns um die Berechnung der Ableitung keine Gedanken machen. Wir initialisieren alle Gewichte $w_1,\\dots,w_5$ mit $0$, d.h. $\\v w^{[0]}=\\v 0$. Das ist gleichbedeutend mit einer Vorhersage von 50% Kaufwahrscheinlichkeit für jeden Kunden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4750 iterations. Final objective is 45.30298215658562\n"
     ]
    }
   ],
   "source": [
    "from autograd import grad\n",
    "\n",
    "def gd(func, alpha, w0, n_steps=10000):\n",
    "    \"\"\" Perform n_steps iterations of gradient descent with steplength alpha and return iterates \"\"\"\n",
    "    w_history = [w0]\n",
    "    w = w0\n",
    "    grad_f = grad(func)\n",
    "    for k in range(n_steps):\n",
    "        \n",
    "        # Abstiegsrichtung\n",
    "        d = -grad_f(w)\n",
    "\n",
    "        # Stop sobald die Norm des Gradienten klein ist\n",
    "        if np.linalg.norm(d) < 1e-6:\n",
    "            break\n",
    "\n",
    "        # Nächste Iterierte\n",
    "        w = w + alpha * d\n",
    "        \n",
    "        w_history.append(w)\n",
    "\n",
    "    return np.array(w_history)\n",
    "\n",
    "# Initialisierung\n",
    "w0 = np.zeros(5)\n",
    "w_history = gd(func=binary_cross_entropy, alpha=0.01, w0=w0)\n",
    "\n",
    "# Lösung ist letzte Iterierte\n",
    "w_opt = w_history[-1]\n",
    "\n",
    "print(f\"Took {len(w_history)} iterations. Final objective is {binary_cross_entropy(w_opt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konvexität der logistischen Regression\n",
    "\n",
    "Als nächstes möchten wir überprüfen, ob ein Newton-Verfahren die Lösung schneller erreicht als das Gradientenverfahren. Dazu ist es hilfreich, zunächst zu überprüfen, ob die Hessematrix überall positiv (semi-)definit ist. Wenn dies nicht der Fall ist, so muss man Vorkehrungen treffen, die verhindern, dass das Newton Verfahren ein Maximum oder einen Sattelpunkt ansteuert. Zum Glück ist dies der Fall.\n",
    "\n",
    "**Satz**\n",
    "\n",
    "Die Hessematrix der binären Kreuzentropie für ein logistisches Regressionsmodell lautet\n",
    "\\begin{align*}\n",
    "\\nabla^2 L(\\v w) = \\v X^T \\v D \\v X,\n",
    "\\end{align*}\n",
    "wobei $\\v D$ eine Diagonalmatrix mit den Einträgen\n",
    "\\begin{align*}\n",
    "\\frac{1}{N}\\sigma(\\v w^T\\v x_i)(1-\\sigma(\\v w^T\\v x_i)),\\quad i=1,\\dots, N\n",
    "\\end{align*}\n",
    "ist. Diese ist positiv semi-definit, daher ist das Minimierungsproblem konvex.\n",
    "\n",
    "---\n",
    "\n",
    "Dieses Resultat stellt sicher, dass die Newton-Richtung tatsächlich eine Abstiegsrichtung ist. Außerdem ist sichergestellt, dass jedes lokale Minimum auch ein globales Minimum ist. Wir benutzen die Methode `hessian` aus dem `autograd`-Paket zur automatischen Auswertung der Hessematrix. Außerdem benötigen wir die Funktion `solve` aus dem Paket `numpy.linalg`, um in jedem Schritt das Gleichungssystem zu lösen, welches uns die Newton-Richtung gibt. Obwohl das Ergebnis das gleiche ist, ist dies effizienter als die Inverse zu berechnen und die rechte Seite damit zu multiplizieren.\n",
    "\n",
    "### Newton-Verfahren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 6 iterations. Final objective is 45.30298215658388\n"
     ]
    }
   ],
   "source": [
    "from autograd import hessian\n",
    "from numpy.linalg import solve\n",
    "\n",
    "def newton(func, w0, n_steps=1000):\n",
    "    \"\"\" Perform n_steps iterations of Newton's method with stepsize 1 and return iterates \"\"\"\n",
    "    w_history = [w0]\n",
    "    w = w0\n",
    "    grad_f = grad(func)\n",
    "    hess_f = hessian(func)\n",
    "    for k in range(n_steps):\n",
    "\n",
    "        # Abstiegsrichtung\n",
    "        g = grad_f(w)\n",
    "        d = solve(hess_f(w), -g)\n",
    "        \n",
    "        # Stop if norm (length) of gradient vector is small\n",
    "        if np.linalg.norm(g) < 1e-6:\n",
    "            break\n",
    "\n",
    "        # Next iterate\n",
    "        w = w + d\n",
    "        \n",
    "        w_history.append(w)\n",
    "\n",
    "    return np.array(w_history)\n",
    "\n",
    "w0 = np.zeros(5)\n",
    "w_history = newton(func=binary_cross_entropy, w0=w0)\n",
    "w_opt = w_history[-1]\n",
    "\n",
    "print(f\"Took {len(w_history)} iterations. Final objective is {binary_cross_entropy(w_opt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Minimum ist nach 6 Iterationen erreicht. Wie erwartet stimmen der Zielfunktionswert der Lösung mit dem Gradientenverfahren und der Lösung, die das Newton-Verfahren produziert hat, überein. Die Koeffizienten $w_1,\\dots,w_5$ quantifizieren den Einfluss der Features $x_1,\\dots,x_5$ auf die Vorhersage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gewichte der Features:\n",
      "Age                 : -0.292\n",
      "Gender              : -0.167\n",
      "Annual Income       :  3.500\n",
      "Browsing Time       : -1.245\n",
      "Previous Purchases  : -0.103\n"
     ]
    }
   ],
   "source": [
    "print(\"Gewichte der Features:\")\n",
    "for i in range(5):\n",
    "    print(f\"{df.columns[i].ljust(20)}: {w_opt[i]: .3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können das trainierte Modell außerdem benutzen um damit Vorhersagen zu machen. Dazu benutzen wir die logistische Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Vorhersage ist in 75 von 100 Fällen korrekt.\n"
     ]
    }
   ],
   "source": [
    "df[\"Purchased Prob\"] = logistic(X, w_opt)\n",
    "df[\"Purchased Pred\"] = df[\"Purchased Prob\"].round()\n",
    "df[\"Vorhersage korrekt?\"] = df[\"Purchased Pred\"] == df[\"Purchased\"]\n",
    "print(f\"Die Vorhersage ist in {df['Vorhersage korrekt?'].sum()} von {len(df)} Fällen korrekt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Browsing Time</th>\n",
       "      <th>Previous Purchases</th>\n",
       "      <th>Purchased</th>\n",
       "      <th>Purchased Prob</th>\n",
       "      <th>Purchased Pred</th>\n",
       "      <th>Vorhersage korrekt?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.048725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.614468</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.116240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955447</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.788221</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.665513</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Gender  Annual Income  Browsing Time  Previous Purchases  Purchased  \\\n",
       "0    22       0             40              5                   0          0   \n",
       "1    35       1             60             10                   3          1   \n",
       "2    26       1             30              3                   1          0   \n",
       "3    29       0             55              8                   2          1   \n",
       "4    42       1             80             12                   4          1   \n",
       "..  ...     ...            ...            ...                 ...        ...   \n",
       "95   24       1             34              3                   1          0   \n",
       "96   37       1             81             13                   4          1   \n",
       "97   28       0             40              5                   1          0   \n",
       "98   33       1             64              9                   3          1   \n",
       "99   30       1             58              8                   2          0   \n",
       "\n",
       "    Purchased Prob  Purchased Pred  Vorhersage korrekt?  \n",
       "0         0.271966             0.0                 True  \n",
       "1         0.502213             1.0                 True  \n",
       "2         0.048725             0.0                 True  \n",
       "3         0.614468             1.0                 True  \n",
       "4         0.949208             1.0                 True  \n",
       "..             ...             ...                  ...  \n",
       "95        0.116240             0.0                 True  \n",
       "96        0.955447             1.0                 True  \n",
       "97        0.196124             0.0                 True  \n",
       "98        0.788221             1.0                 True  \n",
       "99        0.665513             1.0                False  \n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
